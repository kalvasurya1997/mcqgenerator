{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI(openai_api_key=KEY,model_name=\"gpt-4o\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001A0717E1370>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001A0717EBD00>, root_client=<openai.OpenAI object at 0x000001A0717D3B80>, root_async_client=<openai.AsyncOpenAI object at 0x000001A0717E13D0>, model_name='gpt-4o', temperature=0.5, openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. \\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template=TEMPLATE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kalva\\AppData\\Local\\Temp\\ipykernel_23748\\2669661367.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  quiz_chain=LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True)\n"
     ]
    }
   ],
   "source": [
    "quiz_chain=LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2 = \"\"\"\n",
    "You are an expert English grammarian and writer. You are given a multiple-choice quiz designed for {subject} students.\n",
    "Evaluate the complexity of the quiz and provide a complete analysis in no more than 50 words.\n",
    "If the quiz does not match the students' cognitive and analytical abilities, update any questions that need revision and adjust the tone to perfectly suit their level.\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Review the quiz as an expert English writer:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt=PromptTemplate(input_variables=[\"subject\", \"quiz\"], template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain=LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key=\"review\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluate_chain=SequentialChain(chains=[quiz_chain, review_chain], input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "                                        output_variables=[\"quiz\", \"review\"], verbose=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=r\"C:\\Users\\kalva\\mcqgenerator\\data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\kalva\\\\mcqgenerator\\\\data.txt'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'r') as file:\n",
    "    TEXT = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is deep learning?\n",
      "Deep learning is a subset of machine learning that uses multilayered neural networks, called deep neural networks, to simulate the complex decision-making power of the human brain. Some form of deep learning powers most of the artificial intelligence (AI) applications in our lives today.\n",
      "\n",
      "The chief difference between deep learning and machine learning is the structure of the underlying neural network architecture. “Nondeep,” traditional machine learning models use simple neural networks with one or two computational layers. Deep learning models use three or more layers—but typically hundreds or thousands of layers—to train the models.\n",
      "\n",
      "While supervised learning models require structured, labeled input data to make accurate outputs, deep learning models can use unsupervised learning. With unsupervised learning, deep learning models can extract the characteristics, features and relationships they need to make accurate outputs from raw, unstructured data. Additionally, these models can even evaluate and refine their outputs for increased precision.\n",
      "\n",
      "Deep learning is an aspect of data science that drives many applications and services that improve automation, performing analytical and physical tasks without human intervention. This enables many everyday products and services—such as digital assistants, voice-enabled TV remotes, credit card fraud detection, self-driving cars and generative AI.\n",
      "\n",
      "3D design of balls rolling on a track\n",
      "The latest AI News + Insights \n",
      "Discover expertly curated insights and news on AI, cloud and more in the weekly Think Newsletter. \n",
      "\n",
      "Subscribe today\n",
      "How deep learning works\n",
      "Neural networks, or artificial neural networks, attempt to mimic the human brain through a combination of data inputs, weights and bias—all acting as silicon neurons. These elements work together to accurately recognize, classify and describe objects within the data.\n",
      "\n",
      "Deep neural networks consist of multiple layers of interconnected nodes, each building on the previous layer to refine and optimize the prediction or categorization. This progression of computations through the network is called forward propagation. The input and output layers of a deep neural network are called visible layers. The input layer is where the deep learning model ingests the data for processing, and the output layer is where the final prediction or classification is made.\n",
      "\n",
      "Another process called backpropagation uses algorithms, such as gradient descent, to calculate errors in predictions, and then adjusts the weights and biases of the function by moving backwards through the layers to train the model. Together, forward propagation and backpropagation enable a neural network to make predictions and correct for any errors. Over time, the algorithm becomes gradually more accurate.\n",
      "\n",
      "Deep learning requires a tremendous amount of computing power. High-performance graphical processing units (GPUs) are ideal because they can handle a large volume of calculations in multiple cores with copious memory available. Distributed cloud computing might also assist. This level of computing power is necessary to train deep algorithms through deep learning. However, managing multiple GPUs on premises can create a large demand on internal resources and be incredibly costly to scale. For software requirements, most deep learning apps are coded with one of these three learning frameworks: JAX, PyTorch or TensorFlow.\n",
      "\n",
      "Mixture of Experts | 14 February, episode 42\n",
      "\n",
      "Episode 42: Paris AI Summit, Altman's \"Three Observations,\" Anthropic's Economic Index\n",
      "Decoding AI: Weekly News Roundup\n",
      "Join our world-class panel of engineers, researchers, product leaders and more as they cut through the AI noise to bring you the latest in AI news and insights.\n",
      "\n",
      "Watch the latest podcast episodes \n",
      "Types of deep learning models\n",
      "Deep learning algorithms are incredibly complex, and there are different types of neural networks to address specific problems or datasets. Here are six. Each has its own advantages and they are presented here roughly in the order of their development, with each successive model adjusting to overcome a weakness in a previous model.\n",
      "\n",
      "One potential weakness across them all is that deep learning models are often “black boxes,” making it difficult to understand their inner workings and posing interpretability challenges. But this can be balanced against the overall benefits of high accuracy and scalability.\n",
      "\n",
      "CNNs\n",
      "Convolutional neural networks (CNNs or ConvNets) are used primarily in computer vision and image classification applications. They can detect features and patterns within images and videos, enabling tasks such as object detection, image recognition, pattern recognition and face recognition. These networks harness principles from linear algebra, particularly matrix multiplication, to identify patterns within an image.\n",
      "\n",
      "CNNs are a specific type of neural network, which is composed of node layers, containing an input layer, one or more hidden layers and an output layer. Each node connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network.\n",
      "\n",
      "At least three main types of layers make up a CNN: a convolutional layer, pooling layer and fully connected (FC) layer. For complex uses, a CNN might contain up to thousands of layers, each layer building on the previous layers. By “convolution”—working and reworking the original input—detailed patterns can be discovered. With each layer, the CNN increases in its complexity, identifying greater portions of the image. Earlier layers focus on simple features, such as colors and edges. As the image data progresses through the layers of the CNN, it starts to recognize larger elements or shapes of the object until it finally identifies the intended object.\n",
      "\n",
      "CNNs are distinguished from other neural networks by their superior performance with image, speech or audio signal inputs. Before CNNs, manual and time-consuming feature extraction methods were used to identify objects in images. However, CNNs now provide a more scalable approach to image classification and object recognition tasks, and process high-dimensional data. And CNNs can exchange data between layers, to deliver more efficient data processing. While information might be lost in the pooling layer, this might be outweighed by the benefits of CNNs, which can help to reduce complexity, improve efficiency and limit risk of overfitting.\n",
      "\n",
      "There are other disadvantages to CNNs, which are computationally demanding—costing time and budget, requiring many graphical processing units (GPUs). They also require highly trained experts with cross-domain knowledge, and careful testing of configurations, hyperparameters and configurations.\n",
      "\n",
      "RNNs\n",
      "Recurrent neural networks (RNNs) are typically used in natural language and speech recognition applications as they use sequential or time-series data. RNNs can be identified by their feedback loops. These learning algorithms are primarily used when using time-series data to make predictions about future outcomes. Use cases include stock market predictions or sales forecasting, or ordinal or temporal problems, such as language translation, natural language processing (NLP), speech recognition and image captioning. These functions are often incorporated into popular applications such as Siri, voice search and Google Translate.\n",
      "\n",
      "RNNs use their “memory” as they take information from prior inputs to influence the current input and output. While traditional deep neural networks assume that inputs and outputs are independent of each other, the output of RNNs depends on the prior elements within the sequence. While future events would also be helpful in determining the output of a given sequence, unidirectional recurrent neural networks cannot account for these events in their predictions.\n",
      "\n",
      "RNNs share parameters across each layer of the network and share the same weight parameter within each layer of the network, with the weights adjusted through the processes of backpropagation and gradient descent to facilitate reinforcement learning.\n",
      "\n",
      "RNNs use a backpropagation through time (BPTT) algorithm to determine the gradients, which is slightly different from traditional backpropagation as it is specific to sequence data. The principles of BPTT are the same as traditional backpropagation, where the model trains itself by calculating errors from its output layer to its input layer. BPTT differs from the traditional approach in that BPTT sums errors at each time step, whereas feedforward networks do not need to sum errors as they do not share parameters across each layer.\n",
      "\n",
      "An advantage over other neural network types is that RNNs use both binary data processing and memory. RNNs can plan out multiple inputs and productions so that rather than delivering only one result for a single input, RNNs can produce one-to-many, many-to-one or many-to-many outputs.\n",
      "\n",
      "There are also options within RNNs. For example, the long short-term memory (LSTM) network is superior to simple RNNs by learning and acting on longer-term dependencies.\n",
      "\n",
      "However, RNNs tend to run into two basic problems, known as exploding gradients and vanishing gradients. These issues are defined by the size of the gradient, which is the slope of the loss function along the error curve.\n",
      "\n",
      "When the gradient is vanishing and is too small, it continues to become smaller, updating the weight parameters until they become insignificant—that is: zero (0). When that occurs, the algorithm is no longer learning.\n",
      "Exploding gradients occur when the gradient is too large, creating an unstable model. In this case, the model weights grow too large, and they will eventually be represented as NaN (not a number). One solution to these issues is to reduce the number of hidden layers within the neural network, eliminating some of the complexity in the RNN models.\n",
      "Some final disadvantages: RNNs might also require long training time and be difficult to use on large datasets. Optimizing RNNs add complexity when they have many layers and parameters.\n",
      "\n",
      "Autoencoders and variational autoencoders\n",
      "Deep learning made it possible to move beyond the analysis of numerical data, by adding the analysis of images, speech and other complex data types. Among the first class of models to achieve this were variational autoencoders (VAEs). They were the first deep-learning models to be widely used for generating realistic images and speech, which empowered deep generative modeling by making models easier to scale—which is the cornerstone of what we think of as generative AI.\n",
      "\n",
      "Autoencoders work by encoding unlabeled data into a compressed representation, and then decoding the data back into its original form. Plain autoencoders were used for a variety of purposes, including reconstructing corrupted or blurry images. Variational autoencoders added the critical ability not just to reconstruct data, but also to output variations on the original data.\n",
      "\n",
      "This ability to generate novel data ignited a rapid-fire succession of new technologies, from generative adversarial networks (GANs) to diffusion models, capable of producing ever more realistic—but fake—images. In this way, VAEs set the stage for today’s generative AI.\n",
      "\n",
      "Autoencoders are built out of blocks of encoders and decoders, an architecture that also underpins today’s large language models. Encoders compress a dataset into a dense representation, arranging similar data points closer together in an abstract space. Decoders sample from this space to create something new while preserving the dataset’s most important features.\n",
      "\n",
      "The biggest advantage to autoencoders is the ability to handle large batches of data and show input data in a compressed form, so the most significant aspects stand out—enabling anomaly detection and classification tasks. This also speeds transmission and reduces storage requirements. Autoencoders can be trained on unlabeled data so they might be used where labeled data is not available. When unsupervised training is used, there is a time savings advantage: deep learning algorithms learn automatically and gain accuracy without needing manual feature engineering. In addition, VAEs can generate new sample data for text or image generation.\n",
      "\n",
      "There are disadvantages to autoencoders. The training of deep or intricate structures can be a drain on computational resources. And during unsupervised training, the model might overlook the needed properties and instead simply replicate the input data. Autoencoders might also overlook complex data linkages in structured data so that it does not correctly identify complex relationships.\n",
      "\n",
      "GANs\n",
      "Generative adversarial networks (GANs) are neural networks that are used both in and outside of artificial intelligence (AI) to create new data resembling the original training data. These can include images appearing to be human faces—but are generated, not taken of real people. The “adversarial” part of the name comes from the back-and-forth between the two portions of the GAN: a generator and a discriminator.\n",
      "\n",
      "The generator creates something: images, video or audio and then producing an output with a twist. For example, a horse can be transformed into a zebra with some degree of accuracy. The result depends on the input and how well-trained the layers are in the generative model for this use case.\n",
      "The discriminator is the adversary, where the generative result (fake image) is compared against the real images in the dataset. The discriminator tries to distinguish between the real and fake images, video or audio.\n",
      "GANs train themselves. The generator creates fakes while the discriminator learns to spot the differences between the generator's fakes and the true examples. When the discriminator is able to flag the fake, then the generator is penalized. The feedback loop continues until the generator succeeds in producing output that the discriminator cannot distinguish.\n",
      "\n",
      "The prime GAN benefit is creating realistic output that can be difficult to distinguish from the originals, which in turn may be used to further train machine learning models. Setting up a GAN to learn is straightforward, since they are trained by using unlabeled data or with minor labeling. However, the potential disadvantage is that the generator and discriminator might go back-and-forth in competition for a long time, creating a large system drain. One training limitation is that a huge amount of input data might be required to obtain a satisfactory output. Another potential problem is “mode collapse,” when the generator produces a limited set of outputs rather than a wider variety.\n",
      "\n",
      "Diffusion models\n",
      "Diffusion models are generative models that are trained using the forward and reverse diffusion process of progressive noise-addition and denoising. Diffusion models generate data—most often images—similar to the data on which they are trained, but then overwrite the data used to train them. They gradually add Gaussian noise to the training data until it’s unrecognizable, then learn a reversed “denoising” process that can synthesize output (usually images) from random noise input.\n",
      "\n",
      "A diffusion model learns to minimize the differences of the generated samples versus the desired target. Any discrepancy is quantified and the model's parameters are updated to minimize the loss—training the model to produce samples closely resembling the authentic training data.\n",
      "\n",
      "Beyond image quality, diffusion models have the advantage of not requiring adversarial training, which speeds the learning process and also offering close process control. Training is more stable than with GANs and diffusion models are not as prone to mode collapse.\n",
      "\n",
      "But, compared to GANs, diffusion models can require more computing resources to train, including more fine-tuning. IBM Research® has also discovered that this form of generative AI can be hijacked with hidden backdoors, giving attackers control over the image creation process so that AI diffusion models can be tricked into generating manipulated images.\n",
      "\n",
      "Transformer models\n",
      "Transformer models combine an encoder-decoder architecture with a text-processing mechanism and have revolutionized how language models are trained. An encoder converts raw, unannotated text into representations known as embeddings; the decoder takes these embeddings together with previous outputs of the model, and successively predicts each word in a sentence.\n",
      "\n",
      "Using fill-in-the-blank guessing, the encoder learns how words and sentences relate to each other, building up a powerful representation of language without having to label parts of speech and other grammatical features. Transformers, in fact, can be pretrained at the outset without a particular task in mind. After these powerful representations are learned, the models can later be specialized—with much less data—to perform a requested task.\n",
      "\n",
      "Several innovations make this possible. Transformers process words in a sentence simultaneously, enabling text processing in parallel, speeding up training. Earlier techniques including recurrent neural networks (RNNs) processed words one by one. Transformers also learned the positions of words and their relationships—this context enables them to infer meaning and disambiguate words such as “it” in long sentences.\n",
      "\n",
      "By eliminating the need to define a task upfront, transformers made it practical to pretrain language models on vast amounts of raw text, enabling them to grow dramatically in size. Previously, labeled data was gathered to train one model on a specific task. With transformers, one model trained on a massive amount of data can be adapted to multiple tasks by fine-tuning it on a small amount of labeled task-specific data.\n",
      "\n",
      "Language transformers today are used for nongenerative tasks such as classification and entity extraction as well as generative tasks including machine translation, summarization and question answering. Transformers have surprised many people with their ability to generate convincing dialog, essays and other content.\n",
      "\n",
      "Natural language processing (NLP) transformers provide remarkable power since they can run in parallel, processing multiple portions of a sequence simultaneously, which then greatly speeds training. Transformers also track long-term dependencies in text, which enables them to understand the overall context more clearly and create superior output. In addition, transformers are more scalable and flexible in order to be customized by task.\n",
      "\n",
      "As to limitations, because of their complexity, transformers require huge computational resources and a long training time. Also, the training data must be accurately on-target, unbiased and plentiful to produce accurate results.\n",
      "\n",
      "Deep learning use cases\n",
      "The number of uses for deep learning grows every day. Here are just a few of the ways that it is now helping businesses become more efficient and better serve their customers.\n",
      "\n",
      "Application modernization\n",
      "Generative AI can enhance the capabilities of developers and reduce the ever-widening skills gap in the domains of application modernization and IT automation. Generative AI for coding is possible because of recent breakthroughs in large language model (LLM) technologies and natural language processing (NLP). It uses deep learning algorithms and large neural networks trained on vast datasets of existing source code. Training code generally comes from publicly available code produced by open-source projects.\n",
      "\n",
      "Programmers can enter plain text prompts describing what they want the code to do. Generative AI tools suggest code snippets or full functions, streamlining the coding process by handling repetitive tasks and reducing manual coding. Generative AI can also translate code from one language to another, streamlining code conversion or modernization projects, such as updating legacy applications by translating COBOL to Java.\n",
      "\n",
      "Computer vision\n",
      "Computer vision is a field of artificial intelligence (AI) that includes image classification, object detection and semantic segmentation. It uses machine learning and neural networks to teach computers and learning systems to derive meaningful information from digital images, videos and other visual inputs—and to make recommendations or take actions when the system sees defects or issues. If AI enables computers to think, computer vision enables them to see, observe and understand.\n",
      "\n",
      "Because a computer vision system is often trained to inspect products or watch production assets, it usually can analyze thousands of products or processes per minute, noticing imperceptible defects or issues. Computer vision is used in industries that range from energy and utilities to manufacturing and automotive.\n",
      "\n",
      "Computer vision needs lots of data, and then it runs analyses of that data over and over until it discerns and ultimately recognizes images. For example, to train a computer to recognize automobile tires, it needs to be fed vast quantities of tire images and tire-related items to learn the differences and recognize a tire, especially one with no defects.\n",
      "\n",
      "Computer vision uses algorithmic models to enable a computer to teach itself about the context of visual data. If enough data is fed through the model, the computer will “look” at the data and teach itself to tell one image from another. Algorithms enable the machine to learn by itself, rather than with someone programming it to recognize an image.\n",
      "\n",
      "Computer vision enables systems to derive meaningful information from digital images, videos and other visual inputs, and based on those inputs, to take action. This ability to provide recommendations distinguishes it from simple image recognition tasks. Some common applications of computer vision today can be seen in:\n",
      "\n",
      "Automotive: While the age of driverless cars hasn’t entirely arrived, the underlying technology has started to make its way into automobiles, improving driver and passenger safety through features such as lane line detection.\n",
      "\n",
      "Healthcare: Computer vision has been incorporated into radiology technology, enabling doctors to better identify cancerous tumors in healthy anatomy.\n",
      "\n",
      "Marketing: Social media platforms provide suggestions on who might be in a photograph that has been posted on a profile, making it easier to tag friends in photo albums.\n",
      "\n",
      "Retail: Visual search has been incorporated into some e-commerce platforms, enabling brands to recommend items that would complement an existing wardrobe.\n",
      "Customer care\n",
      "AI is helping businesses to better understand and cater to increasing consumer demands. With the rise of highly personalized online shopping, direct-to-consumer models, and delivery services, generative AI can help further unlock a host of benefits that can improve customer care, talent transformation and the performance of applications.\n",
      "\n",
      "AI empowers businesses to adopt a customer-centric approach by harnessing valuable insights from customer feedback and buying habits. This data-driven approach can help improve product design and packaging and can help drive high customer satisfaction and increased sales.\n",
      "\n",
      "Generative AI can also serve as a cognitive assistant for customer care, providing contextual guidance based on conversation history, sentiment analysis and call center transcripts. Also, generative AI can enable personalized shopping experiences, foster customer loyalty and provide a competitive advantage.\n",
      "\n",
      "Digital labor\n",
      "Organizations can augment their workforce by building and deploying robotic process automation (RPA) and digital labor to collaborate with humans to increase productivity, or assist whenever backup is needed. For example, this can help developers speed the updating of legacy software.\n",
      "\n",
      "Digital labor uses foundation models to automate and improve the productivity of knowledge workers by enabling self-service automation in a fast and reliable way—without technical barriers. To automate task performance or calling APIs, an enterprise-grade LLM-based slot filling model can identify information in a conversation and gather all the information required for completing an action or calling an API without much manual effort.\n",
      "\n",
      "Instead of having technical experts record and encode repetitive action flows for knowledge workers, digital labor automations built with a foundation of model-powered conversational instructions and demonstrations can be used by the knowledge worker for self-service automation. For example, to speed app creation, no-code digital apprentices can help end-users, who lack programming expertise, by effectively teaching, supervising and validating code.\n",
      "\n",
      "Generative AI\n",
      "Generative AI (also called gen AI) is a category of AI that autonomously creates text, images, video, data or other content in response to a user’s prompt or request.\n",
      "\n",
      "Generative AI relies on deep learning models that can learn from patterns in existing content and generate new, similar content based on that training. It has applications in many fields—including customer service, marketing, software development and research—and offers enormous potential to streamline enterprise workflows through fast, automated content creation and augmentation.\n",
      "\n",
      "Generative AI excels at handling diverse data sources such as emails, images, videos, audio files and social media content. This unstructured data forms the backbone for creating models and the ongoing training of generative AI, so it can stay effective over time. Using this unstructured data can enhance customer service through chatbots and facilitate more effective email routing. In practice, this might mean guiding users to appropriate resources, whether that’s connecting them with the right agent or directing them to user guides and FAQs.\n",
      "\n",
      "Despite its much-discussed limitations and risks, many businesses are forging ahead, cautiously exploring how their organizations can harness generative AI to improve their internal workflows, and enhance their products and services. This is the new frontier: How to make the workplace more efficient without creating legal or ethical issues.\n",
      "\n",
      "Natural language processing and speech recognition\n",
      "NLP combines computational linguistics—rule-based modeling of human language—with statistical and machine learning models to enable computers and digital devices to recognize, understand and generate text and speech. NLP powers applications and devices that can translate text from one language to another, respond to typed or spoken commands, recognize or authenticate users based on voice. It helps summarize large volumes of text, assess the intent or sentiment of text or speech and generate text or graphics or other content on demand.\n",
      "\n",
      "A subset of NLP is statistical NLP, which combines computer algorithms with machine learning and deep learning models. This approach helps to automatically extract, classify and label elements of text and voice data and then assign a statistical likelihood to each possible meaning of those elements. Today, deep learning models and learning techniques based on RNNs enable NLP systems that “learn” as they work and extract ever more accurate meaning from huge volumes of raw, unstructured and unlabeled text and voice datasets.\n",
      "\n",
      "Speech recognition—also known as automatic speech recognition (ASR), computer speech recognition or speech-to-text—is a capability that enables a program to process human speech into a written format.\n",
      "\n",
      "While speech recognition is commonly confused with voice recognition, speech recognition focuses on the translation of speech from a verbal format to a text one whereas voice recognition just seeks to identify an individual user’s voice.\n",
      "\n",
      "Industry applications\n",
      "Real-world deep learning applications are all around us, and so well integrated into products and services that users are unaware of the complex data processing that is taking place in the background. Some of these examples include:\n",
      "\n",
      "Customer service deep learning\n",
      "Many organizations incorporate deep learning technology into their customer service processes. Chatbots are often used in various applications, services and customer service portals. Traditional chatbots use natural language and even visual recognition, commonly found in call center-like menus. However, more sophisticated chatbot solutions attempt to determine, through learning, if there are multiple responses to ambiguous questions in real time. Based on the responses it receives, the chatbot then tries to answer these questions directly or routes the conversation to a human user.\n",
      "\n",
      "Virtual assistants such as Apple's Siri, Amazon Alexa or Google Assistant extend the idea of a chatbot by enabling speech recognition functionality. This creates a new method to engage users in a personalized way.\n",
      "\n",
      "Financial services analytics\n",
      "Financial institutions regularly use predictive analytics to drive algorithmic trading of stocks, assess business risks for loan approvals, detect fraud, and help manage credit and investment portfolios for clients.\n",
      "\n",
      "Healthcare record-keeping\n",
      "The healthcare industry has benefited greatly from deep learning capabilities ever since the digitization of hospital records and images. Image recognition applications can support medical imaging specialists and radiologists, helping them analyze and assess more images in less time.\n",
      "\n",
      "Law enforcement uses deep learning\n",
      "Deep learning algorithms can analyze and learn from transactional data to identify dangerous patterns that indicate possible fraudulent or criminal activity. Speech recognition, computer vision and other deep learning applications can improve the efficiency and effectiveness of investigative analysis by extracting patterns and evidence from sound and video recordings, images and documents. This capability helps law enforcement analyze large amounts of data more quickly and accurately.\n"
     ]
    }
   ],
   "source": [
    "print(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serialize the Python dictionary into a JSON-formatted string\n",
    "json.dumps(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER=10 \n",
    "SUBJECT=\"Deep Learning\"\n",
    "TONE=\"Intermediate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n",
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text:What is deep learning?\n",
      "Deep learning is a subset of machine learning that uses multilayered neural networks, called deep neural networks, to simulate the complex decision-making power of the human brain. Some form of deep learning powers most of the artificial intelligence (AI) applications in our lives today.\n",
      "\n",
      "The chief difference between deep learning and machine learning is the structure of the underlying neural network architecture. “Nondeep,” traditional machine learning models use simple neural networks with one or two computational layers. Deep learning models use three or more layers—but typically hundreds or thousands of layers—to train the models.\n",
      "\n",
      "While supervised learning models require structured, labeled input data to make accurate outputs, deep learning models can use unsupervised learning. With unsupervised learning, deep learning models can extract the characteristics, features and relationships they need to make accurate outputs from raw, unstructured data. Additionally, these models can even evaluate and refine their outputs for increased precision.\n",
      "\n",
      "Deep learning is an aspect of data science that drives many applications and services that improve automation, performing analytical and physical tasks without human intervention. This enables many everyday products and services—such as digital assistants, voice-enabled TV remotes, credit card fraud detection, self-driving cars and generative AI.\n",
      "\n",
      "3D design of balls rolling on a track\n",
      "The latest AI News + Insights \n",
      "Discover expertly curated insights and news on AI, cloud and more in the weekly Think Newsletter. \n",
      "\n",
      "Subscribe today\n",
      "How deep learning works\n",
      "Neural networks, or artificial neural networks, attempt to mimic the human brain through a combination of data inputs, weights and bias—all acting as silicon neurons. These elements work together to accurately recognize, classify and describe objects within the data.\n",
      "\n",
      "Deep neural networks consist of multiple layers of interconnected nodes, each building on the previous layer to refine and optimize the prediction or categorization. This progression of computations through the network is called forward propagation. The input and output layers of a deep neural network are called visible layers. The input layer is where the deep learning model ingests the data for processing, and the output layer is where the final prediction or classification is made.\n",
      "\n",
      "Another process called backpropagation uses algorithms, such as gradient descent, to calculate errors in predictions, and then adjusts the weights and biases of the function by moving backwards through the layers to train the model. Together, forward propagation and backpropagation enable a neural network to make predictions and correct for any errors. Over time, the algorithm becomes gradually more accurate.\n",
      "\n",
      "Deep learning requires a tremendous amount of computing power. High-performance graphical processing units (GPUs) are ideal because they can handle a large volume of calculations in multiple cores with copious memory available. Distributed cloud computing might also assist. This level of computing power is necessary to train deep algorithms through deep learning. However, managing multiple GPUs on premises can create a large demand on internal resources and be incredibly costly to scale. For software requirements, most deep learning apps are coded with one of these three learning frameworks: JAX, PyTorch or TensorFlow.\n",
      "\n",
      "Mixture of Experts | 14 February, episode 42\n",
      "\n",
      "Episode 42: Paris AI Summit, Altman's \"Three Observations,\" Anthropic's Economic Index\n",
      "Decoding AI: Weekly News Roundup\n",
      "Join our world-class panel of engineers, researchers, product leaders and more as they cut through the AI noise to bring you the latest in AI news and insights.\n",
      "\n",
      "Watch the latest podcast episodes \n",
      "Types of deep learning models\n",
      "Deep learning algorithms are incredibly complex, and there are different types of neural networks to address specific problems or datasets. Here are six. Each has its own advantages and they are presented here roughly in the order of their development, with each successive model adjusting to overcome a weakness in a previous model.\n",
      "\n",
      "One potential weakness across them all is that deep learning models are often “black boxes,” making it difficult to understand their inner workings and posing interpretability challenges. But this can be balanced against the overall benefits of high accuracy and scalability.\n",
      "\n",
      "CNNs\n",
      "Convolutional neural networks (CNNs or ConvNets) are used primarily in computer vision and image classification applications. They can detect features and patterns within images and videos, enabling tasks such as object detection, image recognition, pattern recognition and face recognition. These networks harness principles from linear algebra, particularly matrix multiplication, to identify patterns within an image.\n",
      "\n",
      "CNNs are a specific type of neural network, which is composed of node layers, containing an input layer, one or more hidden layers and an output layer. Each node connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network.\n",
      "\n",
      "At least three main types of layers make up a CNN: a convolutional layer, pooling layer and fully connected (FC) layer. For complex uses, a CNN might contain up to thousands of layers, each layer building on the previous layers. By “convolution”—working and reworking the original input—detailed patterns can be discovered. With each layer, the CNN increases in its complexity, identifying greater portions of the image. Earlier layers focus on simple features, such as colors and edges. As the image data progresses through the layers of the CNN, it starts to recognize larger elements or shapes of the object until it finally identifies the intended object.\n",
      "\n",
      "CNNs are distinguished from other neural networks by their superior performance with image, speech or audio signal inputs. Before CNNs, manual and time-consuming feature extraction methods were used to identify objects in images. However, CNNs now provide a more scalable approach to image classification and object recognition tasks, and process high-dimensional data. And CNNs can exchange data between layers, to deliver more efficient data processing. While information might be lost in the pooling layer, this might be outweighed by the benefits of CNNs, which can help to reduce complexity, improve efficiency and limit risk of overfitting.\n",
      "\n",
      "There are other disadvantages to CNNs, which are computationally demanding—costing time and budget, requiring many graphical processing units (GPUs). They also require highly trained experts with cross-domain knowledge, and careful testing of configurations, hyperparameters and configurations.\n",
      "\n",
      "RNNs\n",
      "Recurrent neural networks (RNNs) are typically used in natural language and speech recognition applications as they use sequential or time-series data. RNNs can be identified by their feedback loops. These learning algorithms are primarily used when using time-series data to make predictions about future outcomes. Use cases include stock market predictions or sales forecasting, or ordinal or temporal problems, such as language translation, natural language processing (NLP), speech recognition and image captioning. These functions are often incorporated into popular applications such as Siri, voice search and Google Translate.\n",
      "\n",
      "RNNs use their “memory” as they take information from prior inputs to influence the current input and output. While traditional deep neural networks assume that inputs and outputs are independent of each other, the output of RNNs depends on the prior elements within the sequence. While future events would also be helpful in determining the output of a given sequence, unidirectional recurrent neural networks cannot account for these events in their predictions.\n",
      "\n",
      "RNNs share parameters across each layer of the network and share the same weight parameter within each layer of the network, with the weights adjusted through the processes of backpropagation and gradient descent to facilitate reinforcement learning.\n",
      "\n",
      "RNNs use a backpropagation through time (BPTT) algorithm to determine the gradients, which is slightly different from traditional backpropagation as it is specific to sequence data. The principles of BPTT are the same as traditional backpropagation, where the model trains itself by calculating errors from its output layer to its input layer. BPTT differs from the traditional approach in that BPTT sums errors at each time step, whereas feedforward networks do not need to sum errors as they do not share parameters across each layer.\n",
      "\n",
      "An advantage over other neural network types is that RNNs use both binary data processing and memory. RNNs can plan out multiple inputs and productions so that rather than delivering only one result for a single input, RNNs can produce one-to-many, many-to-one or many-to-many outputs.\n",
      "\n",
      "There are also options within RNNs. For example, the long short-term memory (LSTM) network is superior to simple RNNs by learning and acting on longer-term dependencies.\n",
      "\n",
      "However, RNNs tend to run into two basic problems, known as exploding gradients and vanishing gradients. These issues are defined by the size of the gradient, which is the slope of the loss function along the error curve.\n",
      "\n",
      "When the gradient is vanishing and is too small, it continues to become smaller, updating the weight parameters until they become insignificant—that is: zero (0). When that occurs, the algorithm is no longer learning.\n",
      "Exploding gradients occur when the gradient is too large, creating an unstable model. In this case, the model weights grow too large, and they will eventually be represented as NaN (not a number). One solution to these issues is to reduce the number of hidden layers within the neural network, eliminating some of the complexity in the RNN models.\n",
      "Some final disadvantages: RNNs might also require long training time and be difficult to use on large datasets. Optimizing RNNs add complexity when they have many layers and parameters.\n",
      "\n",
      "Autoencoders and variational autoencoders\n",
      "Deep learning made it possible to move beyond the analysis of numerical data, by adding the analysis of images, speech and other complex data types. Among the first class of models to achieve this were variational autoencoders (VAEs). They were the first deep-learning models to be widely used for generating realistic images and speech, which empowered deep generative modeling by making models easier to scale—which is the cornerstone of what we think of as generative AI.\n",
      "\n",
      "Autoencoders work by encoding unlabeled data into a compressed representation, and then decoding the data back into its original form. Plain autoencoders were used for a variety of purposes, including reconstructing corrupted or blurry images. Variational autoencoders added the critical ability not just to reconstruct data, but also to output variations on the original data.\n",
      "\n",
      "This ability to generate novel data ignited a rapid-fire succession of new technologies, from generative adversarial networks (GANs) to diffusion models, capable of producing ever more realistic—but fake—images. In this way, VAEs set the stage for today’s generative AI.\n",
      "\n",
      "Autoencoders are built out of blocks of encoders and decoders, an architecture that also underpins today’s large language models. Encoders compress a dataset into a dense representation, arranging similar data points closer together in an abstract space. Decoders sample from this space to create something new while preserving the dataset’s most important features.\n",
      "\n",
      "The biggest advantage to autoencoders is the ability to handle large batches of data and show input data in a compressed form, so the most significant aspects stand out—enabling anomaly detection and classification tasks. This also speeds transmission and reduces storage requirements. Autoencoders can be trained on unlabeled data so they might be used where labeled data is not available. When unsupervised training is used, there is a time savings advantage: deep learning algorithms learn automatically and gain accuracy without needing manual feature engineering. In addition, VAEs can generate new sample data for text or image generation.\n",
      "\n",
      "There are disadvantages to autoencoders. The training of deep or intricate structures can be a drain on computational resources. And during unsupervised training, the model might overlook the needed properties and instead simply replicate the input data. Autoencoders might also overlook complex data linkages in structured data so that it does not correctly identify complex relationships.\n",
      "\n",
      "GANs\n",
      "Generative adversarial networks (GANs) are neural networks that are used both in and outside of artificial intelligence (AI) to create new data resembling the original training data. These can include images appearing to be human faces—but are generated, not taken of real people. The “adversarial” part of the name comes from the back-and-forth between the two portions of the GAN: a generator and a discriminator.\n",
      "\n",
      "The generator creates something: images, video or audio and then producing an output with a twist. For example, a horse can be transformed into a zebra with some degree of accuracy. The result depends on the input and how well-trained the layers are in the generative model for this use case.\n",
      "The discriminator is the adversary, where the generative result (fake image) is compared against the real images in the dataset. The discriminator tries to distinguish between the real and fake images, video or audio.\n",
      "GANs train themselves. The generator creates fakes while the discriminator learns to spot the differences between the generator's fakes and the true examples. When the discriminator is able to flag the fake, then the generator is penalized. The feedback loop continues until the generator succeeds in producing output that the discriminator cannot distinguish.\n",
      "\n",
      "The prime GAN benefit is creating realistic output that can be difficult to distinguish from the originals, which in turn may be used to further train machine learning models. Setting up a GAN to learn is straightforward, since they are trained by using unlabeled data or with minor labeling. However, the potential disadvantage is that the generator and discriminator might go back-and-forth in competition for a long time, creating a large system drain. One training limitation is that a huge amount of input data might be required to obtain a satisfactory output. Another potential problem is “mode collapse,” when the generator produces a limited set of outputs rather than a wider variety.\n",
      "\n",
      "Diffusion models\n",
      "Diffusion models are generative models that are trained using the forward and reverse diffusion process of progressive noise-addition and denoising. Diffusion models generate data—most often images—similar to the data on which they are trained, but then overwrite the data used to train them. They gradually add Gaussian noise to the training data until it’s unrecognizable, then learn a reversed “denoising” process that can synthesize output (usually images) from random noise input.\n",
      "\n",
      "A diffusion model learns to minimize the differences of the generated samples versus the desired target. Any discrepancy is quantified and the model's parameters are updated to minimize the loss—training the model to produce samples closely resembling the authentic training data.\n",
      "\n",
      "Beyond image quality, diffusion models have the advantage of not requiring adversarial training, which speeds the learning process and also offering close process control. Training is more stable than with GANs and diffusion models are not as prone to mode collapse.\n",
      "\n",
      "But, compared to GANs, diffusion models can require more computing resources to train, including more fine-tuning. IBM Research® has also discovered that this form of generative AI can be hijacked with hidden backdoors, giving attackers control over the image creation process so that AI diffusion models can be tricked into generating manipulated images.\n",
      "\n",
      "Transformer models\n",
      "Transformer models combine an encoder-decoder architecture with a text-processing mechanism and have revolutionized how language models are trained. An encoder converts raw, unannotated text into representations known as embeddings; the decoder takes these embeddings together with previous outputs of the model, and successively predicts each word in a sentence.\n",
      "\n",
      "Using fill-in-the-blank guessing, the encoder learns how words and sentences relate to each other, building up a powerful representation of language without having to label parts of speech and other grammatical features. Transformers, in fact, can be pretrained at the outset without a particular task in mind. After these powerful representations are learned, the models can later be specialized—with much less data—to perform a requested task.\n",
      "\n",
      "Several innovations make this possible. Transformers process words in a sentence simultaneously, enabling text processing in parallel, speeding up training. Earlier techniques including recurrent neural networks (RNNs) processed words one by one. Transformers also learned the positions of words and their relationships—this context enables them to infer meaning and disambiguate words such as “it” in long sentences.\n",
      "\n",
      "By eliminating the need to define a task upfront, transformers made it practical to pretrain language models on vast amounts of raw text, enabling them to grow dramatically in size. Previously, labeled data was gathered to train one model on a specific task. With transformers, one model trained on a massive amount of data can be adapted to multiple tasks by fine-tuning it on a small amount of labeled task-specific data.\n",
      "\n",
      "Language transformers today are used for nongenerative tasks such as classification and entity extraction as well as generative tasks including machine translation, summarization and question answering. Transformers have surprised many people with their ability to generate convincing dialog, essays and other content.\n",
      "\n",
      "Natural language processing (NLP) transformers provide remarkable power since they can run in parallel, processing multiple portions of a sequence simultaneously, which then greatly speeds training. Transformers also track long-term dependencies in text, which enables them to understand the overall context more clearly and create superior output. In addition, transformers are more scalable and flexible in order to be customized by task.\n",
      "\n",
      "As to limitations, because of their complexity, transformers require huge computational resources and a long training time. Also, the training data must be accurately on-target, unbiased and plentiful to produce accurate results.\n",
      "\n",
      "Deep learning use cases\n",
      "The number of uses for deep learning grows every day. Here are just a few of the ways that it is now helping businesses become more efficient and better serve their customers.\n",
      "\n",
      "Application modernization\n",
      "Generative AI can enhance the capabilities of developers and reduce the ever-widening skills gap in the domains of application modernization and IT automation. Generative AI for coding is possible because of recent breakthroughs in large language model (LLM) technologies and natural language processing (NLP). It uses deep learning algorithms and large neural networks trained on vast datasets of existing source code. Training code generally comes from publicly available code produced by open-source projects.\n",
      "\n",
      "Programmers can enter plain text prompts describing what they want the code to do. Generative AI tools suggest code snippets or full functions, streamlining the coding process by handling repetitive tasks and reducing manual coding. Generative AI can also translate code from one language to another, streamlining code conversion or modernization projects, such as updating legacy applications by translating COBOL to Java.\n",
      "\n",
      "Computer vision\n",
      "Computer vision is a field of artificial intelligence (AI) that includes image classification, object detection and semantic segmentation. It uses machine learning and neural networks to teach computers and learning systems to derive meaningful information from digital images, videos and other visual inputs—and to make recommendations or take actions when the system sees defects or issues. If AI enables computers to think, computer vision enables them to see, observe and understand.\n",
      "\n",
      "Because a computer vision system is often trained to inspect products or watch production assets, it usually can analyze thousands of products or processes per minute, noticing imperceptible defects or issues. Computer vision is used in industries that range from energy and utilities to manufacturing and automotive.\n",
      "\n",
      "Computer vision needs lots of data, and then it runs analyses of that data over and over until it discerns and ultimately recognizes images. For example, to train a computer to recognize automobile tires, it needs to be fed vast quantities of tire images and tire-related items to learn the differences and recognize a tire, especially one with no defects.\n",
      "\n",
      "Computer vision uses algorithmic models to enable a computer to teach itself about the context of visual data. If enough data is fed through the model, the computer will “look” at the data and teach itself to tell one image from another. Algorithms enable the machine to learn by itself, rather than with someone programming it to recognize an image.\n",
      "\n",
      "Computer vision enables systems to derive meaningful information from digital images, videos and other visual inputs, and based on those inputs, to take action. This ability to provide recommendations distinguishes it from simple image recognition tasks. Some common applications of computer vision today can be seen in:\n",
      "\n",
      "Automotive: While the age of driverless cars hasn’t entirely arrived, the underlying technology has started to make its way into automobiles, improving driver and passenger safety through features such as lane line detection.\n",
      "\n",
      "Healthcare: Computer vision has been incorporated into radiology technology, enabling doctors to better identify cancerous tumors in healthy anatomy.\n",
      "\n",
      "Marketing: Social media platforms provide suggestions on who might be in a photograph that has been posted on a profile, making it easier to tag friends in photo albums.\n",
      "\n",
      "Retail: Visual search has been incorporated into some e-commerce platforms, enabling brands to recommend items that would complement an existing wardrobe.\n",
      "Customer care\n",
      "AI is helping businesses to better understand and cater to increasing consumer demands. With the rise of highly personalized online shopping, direct-to-consumer models, and delivery services, generative AI can help further unlock a host of benefits that can improve customer care, talent transformation and the performance of applications.\n",
      "\n",
      "AI empowers businesses to adopt a customer-centric approach by harnessing valuable insights from customer feedback and buying habits. This data-driven approach can help improve product design and packaging and can help drive high customer satisfaction and increased sales.\n",
      "\n",
      "Generative AI can also serve as a cognitive assistant for customer care, providing contextual guidance based on conversation history, sentiment analysis and call center transcripts. Also, generative AI can enable personalized shopping experiences, foster customer loyalty and provide a competitive advantage.\n",
      "\n",
      "Digital labor\n",
      "Organizations can augment their workforce by building and deploying robotic process automation (RPA) and digital labor to collaborate with humans to increase productivity, or assist whenever backup is needed. For example, this can help developers speed the updating of legacy software.\n",
      "\n",
      "Digital labor uses foundation models to automate and improve the productivity of knowledge workers by enabling self-service automation in a fast and reliable way—without technical barriers. To automate task performance or calling APIs, an enterprise-grade LLM-based slot filling model can identify information in a conversation and gather all the information required for completing an action or calling an API without much manual effort.\n",
      "\n",
      "Instead of having technical experts record and encode repetitive action flows for knowledge workers, digital labor automations built with a foundation of model-powered conversational instructions and demonstrations can be used by the knowledge worker for self-service automation. For example, to speed app creation, no-code digital apprentices can help end-users, who lack programming expertise, by effectively teaching, supervising and validating code.\n",
      "\n",
      "Generative AI\n",
      "Generative AI (also called gen AI) is a category of AI that autonomously creates text, images, video, data or other content in response to a user’s prompt or request.\n",
      "\n",
      "Generative AI relies on deep learning models that can learn from patterns in existing content and generate new, similar content based on that training. It has applications in many fields—including customer service, marketing, software development and research—and offers enormous potential to streamline enterprise workflows through fast, automated content creation and augmentation.\n",
      "\n",
      "Generative AI excels at handling diverse data sources such as emails, images, videos, audio files and social media content. This unstructured data forms the backbone for creating models and the ongoing training of generative AI, so it can stay effective over time. Using this unstructured data can enhance customer service through chatbots and facilitate more effective email routing. In practice, this might mean guiding users to appropriate resources, whether that’s connecting them with the right agent or directing them to user guides and FAQs.\n",
      "\n",
      "Despite its much-discussed limitations and risks, many businesses are forging ahead, cautiously exploring how their organizations can harness generative AI to improve their internal workflows, and enhance their products and services. This is the new frontier: How to make the workplace more efficient without creating legal or ethical issues.\n",
      "\n",
      "Natural language processing and speech recognition\n",
      "NLP combines computational linguistics—rule-based modeling of human language—with statistical and machine learning models to enable computers and digital devices to recognize, understand and generate text and speech. NLP powers applications and devices that can translate text from one language to another, respond to typed or spoken commands, recognize or authenticate users based on voice. It helps summarize large volumes of text, assess the intent or sentiment of text or speech and generate text or graphics or other content on demand.\n",
      "\n",
      "A subset of NLP is statistical NLP, which combines computer algorithms with machine learning and deep learning models. This approach helps to automatically extract, classify and label elements of text and voice data and then assign a statistical likelihood to each possible meaning of those elements. Today, deep learning models and learning techniques based on RNNs enable NLP systems that “learn” as they work and extract ever more accurate meaning from huge volumes of raw, unstructured and unlabeled text and voice datasets.\n",
      "\n",
      "Speech recognition—also known as automatic speech recognition (ASR), computer speech recognition or speech-to-text—is a capability that enables a program to process human speech into a written format.\n",
      "\n",
      "While speech recognition is commonly confused with voice recognition, speech recognition focuses on the translation of speech from a verbal format to a text one whereas voice recognition just seeks to identify an individual user’s voice.\n",
      "\n",
      "Industry applications\n",
      "Real-world deep learning applications are all around us, and so well integrated into products and services that users are unaware of the complex data processing that is taking place in the background. Some of these examples include:\n",
      "\n",
      "Customer service deep learning\n",
      "Many organizations incorporate deep learning technology into their customer service processes. Chatbots are often used in various applications, services and customer service portals. Traditional chatbots use natural language and even visual recognition, commonly found in call center-like menus. However, more sophisticated chatbot solutions attempt to determine, through learning, if there are multiple responses to ambiguous questions in real time. Based on the responses it receives, the chatbot then tries to answer these questions directly or routes the conversation to a human user.\n",
      "\n",
      "Virtual assistants such as Apple's Siri, Amazon Alexa or Google Assistant extend the idea of a chatbot by enabling speech recognition functionality. This creates a new method to engage users in a personalized way.\n",
      "\n",
      "Financial services analytics\n",
      "Financial institutions regularly use predictive analytics to drive algorithmic trading of stocks, assess business risks for loan approvals, detect fraud, and help manage credit and investment portfolios for clients.\n",
      "\n",
      "Healthcare record-keeping\n",
      "The healthcare industry has benefited greatly from deep learning capabilities ever since the digitization of hospital records and images. Image recognition applications can support medical imaging specialists and radiologists, helping them analyze and assess more images in less time.\n",
      "\n",
      "Law enforcement uses deep learning\n",
      "Deep learning algorithms can analyze and learn from transactional data to identify dangerous patterns that indicate possible fraudulent or criminal activity. Speech recognition, computer vision and other deep learning applications can improve the efficiency and effectiveness of investigative analysis by extracting patterns and evidence from sound and video recordings, images and documents. This capability helps law enforcement analyze large amounts of data more quickly and accurately.\n",
      "You are an expert MCQ maker. Given the above text, it is your job to create a quiz  of 10 multiple choice questions for Deep Learning students in Intermediate tone. \n",
      "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
      "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. Ensure to make 10 MCQs\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text:What is deep learning?\n",
      "Deep learning is a subset of machine learning that uses multilayered neural networks, called deep neural networks, to simulate the complex decision-making power of the human brain. Some form of deep learning powers most of the artificial intelligence (AI) applications in our lives today.\n",
      "\n",
      "The chief difference between deep learning and machine learning is the structure of the underlying neural network architecture. “Nondeep,” traditional machine learning models use simple neural networks with one or two computational layers. Deep learning models use three or more layers—but typically hundreds or thousands of layers—to train the models.\n",
      "\n",
      "While supervised learning models require structured, labeled input data to make accurate outputs, deep learning models can use unsupervised learning. With unsupervised learning, deep learning models can extract the characteristics, features and relationships they need to make accurate outputs from raw, unstructured data. Additionally, these models can even evaluate and refine their outputs for increased precision.\n",
      "\n",
      "Deep learning is an aspect of data science that drives many applications and services that improve automation, performing analytical and physical tasks without human intervention. This enables many everyday products and services—such as digital assistants, voice-enabled TV remotes, credit card fraud detection, self-driving cars and generative AI.\n",
      "\n",
      "3D design of balls rolling on a track\n",
      "The latest AI News + Insights \n",
      "Discover expertly curated insights and news on AI, cloud and more in the weekly Think Newsletter. \n",
      "\n",
      "Subscribe today\n",
      "How deep learning works\n",
      "Neural networks, or artificial neural networks, attempt to mimic the human brain through a combination of data inputs, weights and bias—all acting as silicon neurons. These elements work together to accurately recognize, classify and describe objects within the data.\n",
      "\n",
      "Deep neural networks consist of multiple layers of interconnected nodes, each building on the previous layer to refine and optimize the prediction or categorization. This progression of computations through the network is called forward propagation. The input and output layers of a deep neural network are called visible layers. The input layer is where the deep learning model ingests the data for processing, and the output layer is where the final prediction or classification is made.\n",
      "\n",
      "Another process called backpropagation uses algorithms, such as gradient descent, to calculate errors in predictions, and then adjusts the weights and biases of the function by moving backwards through the layers to train the model. Together, forward propagation and backpropagation enable a neural network to make predictions and correct for any errors. Over time, the algorithm becomes gradually more accurate.\n",
      "\n",
      "Deep learning requires a tremendous amount of computing power. High-performance graphical processing units (GPUs) are ideal because they can handle a large volume of calculations in multiple cores with copious memory available. Distributed cloud computing might also assist. This level of computing power is necessary to train deep algorithms through deep learning. However, managing multiple GPUs on premises can create a large demand on internal resources and be incredibly costly to scale. For software requirements, most deep learning apps are coded with one of these three learning frameworks: JAX, PyTorch or TensorFlow.\n",
      "\n",
      "Mixture of Experts | 14 February, episode 42\n",
      "\n",
      "Episode 42: Paris AI Summit, Altman's \"Three Observations,\" Anthropic's Economic Index\n",
      "Decoding AI: Weekly News Roundup\n",
      "Join our world-class panel of engineers, researchers, product leaders and more as they cut through the AI noise to bring you the latest in AI news and insights.\n",
      "\n",
      "Watch the latest podcast episodes \n",
      "Types of deep learning models\n",
      "Deep learning algorithms are incredibly complex, and there are different types of neural networks to address specific problems or datasets. Here are six. Each has its own advantages and they are presented here roughly in the order of their development, with each successive model adjusting to overcome a weakness in a previous model.\n",
      "\n",
      "One potential weakness across them all is that deep learning models are often “black boxes,” making it difficult to understand their inner workings and posing interpretability challenges. But this can be balanced against the overall benefits of high accuracy and scalability.\n",
      "\n",
      "CNNs\n",
      "Convolutional neural networks (CNNs or ConvNets) are used primarily in computer vision and image classification applications. They can detect features and patterns within images and videos, enabling tasks such as object detection, image recognition, pattern recognition and face recognition. These networks harness principles from linear algebra, particularly matrix multiplication, to identify patterns within an image.\n",
      "\n",
      "CNNs are a specific type of neural network, which is composed of node layers, containing an input layer, one or more hidden layers and an output layer. Each node connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network.\n",
      "\n",
      "At least three main types of layers make up a CNN: a convolutional layer, pooling layer and fully connected (FC) layer. For complex uses, a CNN might contain up to thousands of layers, each layer building on the previous layers. By “convolution”—working and reworking the original input—detailed patterns can be discovered. With each layer, the CNN increases in its complexity, identifying greater portions of the image. Earlier layers focus on simple features, such as colors and edges. As the image data progresses through the layers of the CNN, it starts to recognize larger elements or shapes of the object until it finally identifies the intended object.\n",
      "\n",
      "CNNs are distinguished from other neural networks by their superior performance with image, speech or audio signal inputs. Before CNNs, manual and time-consuming feature extraction methods were used to identify objects in images. However, CNNs now provide a more scalable approach to image classification and object recognition tasks, and process high-dimensional data. And CNNs can exchange data between layers, to deliver more efficient data processing. While information might be lost in the pooling layer, this might be outweighed by the benefits of CNNs, which can help to reduce complexity, improve efficiency and limit risk of overfitting.\n",
      "\n",
      "There are other disadvantages to CNNs, which are computationally demanding—costing time and budget, requiring many graphical processing units (GPUs). They also require highly trained experts with cross-domain knowledge, and careful testing of configurations, hyperparameters and configurations.\n",
      "\n",
      "RNNs\n",
      "Recurrent neural networks (RNNs) are typically used in natural language and speech recognition applications as they use sequential or time-series data. RNNs can be identified by their feedback loops. These learning algorithms are primarily used when using time-series data to make predictions about future outcomes. Use cases include stock market predictions or sales forecasting, or ordinal or temporal problems, such as language translation, natural language processing (NLP), speech recognition and image captioning. These functions are often incorporated into popular applications such as Siri, voice search and Google Translate.\n",
      "\n",
      "RNNs use their “memory” as they take information from prior inputs to influence the current input and output. While traditional deep neural networks assume that inputs and outputs are independent of each other, the output of RNNs depends on the prior elements within the sequence. While future events would also be helpful in determining the output of a given sequence, unidirectional recurrent neural networks cannot account for these events in their predictions.\n",
      "\n",
      "RNNs share parameters across each layer of the network and share the same weight parameter within each layer of the network, with the weights adjusted through the processes of backpropagation and gradient descent to facilitate reinforcement learning.\n",
      "\n",
      "RNNs use a backpropagation through time (BPTT) algorithm to determine the gradients, which is slightly different from traditional backpropagation as it is specific to sequence data. The principles of BPTT are the same as traditional backpropagation, where the model trains itself by calculating errors from its output layer to its input layer. BPTT differs from the traditional approach in that BPTT sums errors at each time step, whereas feedforward networks do not need to sum errors as they do not share parameters across each layer.\n",
      "\n",
      "An advantage over other neural network types is that RNNs use both binary data processing and memory. RNNs can plan out multiple inputs and productions so that rather than delivering only one result for a single input, RNNs can produce one-to-many, many-to-one or many-to-many outputs.\n",
      "\n",
      "There are also options within RNNs. For example, the long short-term memory (LSTM) network is superior to simple RNNs by learning and acting on longer-term dependencies.\n",
      "\n",
      "However, RNNs tend to run into two basic problems, known as exploding gradients and vanishing gradients. These issues are defined by the size of the gradient, which is the slope of the loss function along the error curve.\n",
      "\n",
      "When the gradient is vanishing and is too small, it continues to become smaller, updating the weight parameters until they become insignificant—that is: zero (0). When that occurs, the algorithm is no longer learning.\n",
      "Exploding gradients occur when the gradient is too large, creating an unstable model. In this case, the model weights grow too large, and they will eventually be represented as NaN (not a number). One solution to these issues is to reduce the number of hidden layers within the neural network, eliminating some of the complexity in the RNN models.\n",
      "Some final disadvantages: RNNs might also require long training time and be difficult to use on large datasets. Optimizing RNNs add complexity when they have many layers and parameters.\n",
      "\n",
      "Autoencoders and variational autoencoders\n",
      "Deep learning made it possible to move beyond the analysis of numerical data, by adding the analysis of images, speech and other complex data types. Among the first class of models to achieve this were variational autoencoders (VAEs). They were the first deep-learning models to be widely used for generating realistic images and speech, which empowered deep generative modeling by making models easier to scale—which is the cornerstone of what we think of as generative AI.\n",
      "\n",
      "Autoencoders work by encoding unlabeled data into a compressed representation, and then decoding the data back into its original form. Plain autoencoders were used for a variety of purposes, including reconstructing corrupted or blurry images. Variational autoencoders added the critical ability not just to reconstruct data, but also to output variations on the original data.\n",
      "\n",
      "This ability to generate novel data ignited a rapid-fire succession of new technologies, from generative adversarial networks (GANs) to diffusion models, capable of producing ever more realistic—but fake—images. In this way, VAEs set the stage for today’s generative AI.\n",
      "\n",
      "Autoencoders are built out of blocks of encoders and decoders, an architecture that also underpins today’s large language models. Encoders compress a dataset into a dense representation, arranging similar data points closer together in an abstract space. Decoders sample from this space to create something new while preserving the dataset’s most important features.\n",
      "\n",
      "The biggest advantage to autoencoders is the ability to handle large batches of data and show input data in a compressed form, so the most significant aspects stand out—enabling anomaly detection and classification tasks. This also speeds transmission and reduces storage requirements. Autoencoders can be trained on unlabeled data so they might be used where labeled data is not available. When unsupervised training is used, there is a time savings advantage: deep learning algorithms learn automatically and gain accuracy without needing manual feature engineering. In addition, VAEs can generate new sample data for text or image generation.\n",
      "\n",
      "There are disadvantages to autoencoders. The training of deep or intricate structures can be a drain on computational resources. And during unsupervised training, the model might overlook the needed properties and instead simply replicate the input data. Autoencoders might also overlook complex data linkages in structured data so that it does not correctly identify complex relationships.\n",
      "\n",
      "GANs\n",
      "Generative adversarial networks (GANs) are neural networks that are used both in and outside of artificial intelligence (AI) to create new data resembling the original training data. These can include images appearing to be human faces—but are generated, not taken of real people. The “adversarial” part of the name comes from the back-and-forth between the two portions of the GAN: a generator and a discriminator.\n",
      "\n",
      "The generator creates something: images, video or audio and then producing an output with a twist. For example, a horse can be transformed into a zebra with some degree of accuracy. The result depends on the input and how well-trained the layers are in the generative model for this use case.\n",
      "The discriminator is the adversary, where the generative result (fake image) is compared against the real images in the dataset. The discriminator tries to distinguish between the real and fake images, video or audio.\n",
      "GANs train themselves. The generator creates fakes while the discriminator learns to spot the differences between the generator's fakes and the true examples. When the discriminator is able to flag the fake, then the generator is penalized. The feedback loop continues until the generator succeeds in producing output that the discriminator cannot distinguish.\n",
      "\n",
      "The prime GAN benefit is creating realistic output that can be difficult to distinguish from the originals, which in turn may be used to further train machine learning models. Setting up a GAN to learn is straightforward, since they are trained by using unlabeled data or with minor labeling. However, the potential disadvantage is that the generator and discriminator might go back-and-forth in competition for a long time, creating a large system drain. One training limitation is that a huge amount of input data might be required to obtain a satisfactory output. Another potential problem is “mode collapse,” when the generator produces a limited set of outputs rather than a wider variety.\n",
      "\n",
      "Diffusion models\n",
      "Diffusion models are generative models that are trained using the forward and reverse diffusion process of progressive noise-addition and denoising. Diffusion models generate data—most often images—similar to the data on which they are trained, but then overwrite the data used to train them. They gradually add Gaussian noise to the training data until it’s unrecognizable, then learn a reversed “denoising” process that can synthesize output (usually images) from random noise input.\n",
      "\n",
      "A diffusion model learns to minimize the differences of the generated samples versus the desired target. Any discrepancy is quantified and the model's parameters are updated to minimize the loss—training the model to produce samples closely resembling the authentic training data.\n",
      "\n",
      "Beyond image quality, diffusion models have the advantage of not requiring adversarial training, which speeds the learning process and also offering close process control. Training is more stable than with GANs and diffusion models are not as prone to mode collapse.\n",
      "\n",
      "But, compared to GANs, diffusion models can require more computing resources to train, including more fine-tuning. IBM Research® has also discovered that this form of generative AI can be hijacked with hidden backdoors, giving attackers control over the image creation process so that AI diffusion models can be tricked into generating manipulated images.\n",
      "\n",
      "Transformer models\n",
      "Transformer models combine an encoder-decoder architecture with a text-processing mechanism and have revolutionized how language models are trained. An encoder converts raw, unannotated text into representations known as embeddings; the decoder takes these embeddings together with previous outputs of the model, and successively predicts each word in a sentence.\n",
      "\n",
      "Using fill-in-the-blank guessing, the encoder learns how words and sentences relate to each other, building up a powerful representation of language without having to label parts of speech and other grammatical features. Transformers, in fact, can be pretrained at the outset without a particular task in mind. After these powerful representations are learned, the models can later be specialized—with much less data—to perform a requested task.\n",
      "\n",
      "Several innovations make this possible. Transformers process words in a sentence simultaneously, enabling text processing in parallel, speeding up training. Earlier techniques including recurrent neural networks (RNNs) processed words one by one. Transformers also learned the positions of words and their relationships—this context enables them to infer meaning and disambiguate words such as “it” in long sentences.\n",
      "\n",
      "By eliminating the need to define a task upfront, transformers made it practical to pretrain language models on vast amounts of raw text, enabling them to grow dramatically in size. Previously, labeled data was gathered to train one model on a specific task. With transformers, one model trained on a massive amount of data can be adapted to multiple tasks by fine-tuning it on a small amount of labeled task-specific data.\n",
      "\n",
      "Language transformers today are used for nongenerative tasks such as classification and entity extraction as well as generative tasks including machine translation, summarization and question answering. Transformers have surprised many people with their ability to generate convincing dialog, essays and other content.\n",
      "\n",
      "Natural language processing (NLP) transformers provide remarkable power since they can run in parallel, processing multiple portions of a sequence simultaneously, which then greatly speeds training. Transformers also track long-term dependencies in text, which enables them to understand the overall context more clearly and create superior output. In addition, transformers are more scalable and flexible in order to be customized by task.\n",
      "\n",
      "As to limitations, because of their complexity, transformers require huge computational resources and a long training time. Also, the training data must be accurately on-target, unbiased and plentiful to produce accurate results.\n",
      "\n",
      "Deep learning use cases\n",
      "The number of uses for deep learning grows every day. Here are just a few of the ways that it is now helping businesses become more efficient and better serve their customers.\n",
      "\n",
      "Application modernization\n",
      "Generative AI can enhance the capabilities of developers and reduce the ever-widening skills gap in the domains of application modernization and IT automation. Generative AI for coding is possible because of recent breakthroughs in large language model (LLM) technologies and natural language processing (NLP). It uses deep learning algorithms and large neural networks trained on vast datasets of existing source code. Training code generally comes from publicly available code produced by open-source projects.\n",
      "\n",
      "Programmers can enter plain text prompts describing what they want the code to do. Generative AI tools suggest code snippets or full functions, streamlining the coding process by handling repetitive tasks and reducing manual coding. Generative AI can also translate code from one language to another, streamlining code conversion or modernization projects, such as updating legacy applications by translating COBOL to Java.\n",
      "\n",
      "Computer vision\n",
      "Computer vision is a field of artificial intelligence (AI) that includes image classification, object detection and semantic segmentation. It uses machine learning and neural networks to teach computers and learning systems to derive meaningful information from digital images, videos and other visual inputs—and to make recommendations or take actions when the system sees defects or issues. If AI enables computers to think, computer vision enables them to see, observe and understand.\n",
      "\n",
      "Because a computer vision system is often trained to inspect products or watch production assets, it usually can analyze thousands of products or processes per minute, noticing imperceptible defects or issues. Computer vision is used in industries that range from energy and utilities to manufacturing and automotive.\n",
      "\n",
      "Computer vision needs lots of data, and then it runs analyses of that data over and over until it discerns and ultimately recognizes images. For example, to train a computer to recognize automobile tires, it needs to be fed vast quantities of tire images and tire-related items to learn the differences and recognize a tire, especially one with no defects.\n",
      "\n",
      "Computer vision uses algorithmic models to enable a computer to teach itself about the context of visual data. If enough data is fed through the model, the computer will “look” at the data and teach itself to tell one image from another. Algorithms enable the machine to learn by itself, rather than with someone programming it to recognize an image.\n",
      "\n",
      "Computer vision enables systems to derive meaningful information from digital images, videos and other visual inputs, and based on those inputs, to take action. This ability to provide recommendations distinguishes it from simple image recognition tasks. Some common applications of computer vision today can be seen in:\n",
      "\n",
      "Automotive: While the age of driverless cars hasn’t entirely arrived, the underlying technology has started to make its way into automobiles, improving driver and passenger safety through features such as lane line detection.\n",
      "\n",
      "Healthcare: Computer vision has been incorporated into radiology technology, enabling doctors to better identify cancerous tumors in healthy anatomy.\n",
      "\n",
      "Marketing: Social media platforms provide suggestions on who might be in a photograph that has been posted on a profile, making it easier to tag friends in photo albums.\n",
      "\n",
      "Retail: Visual search has been incorporated into some e-commerce platforms, enabling brands to recommend items that would complement an existing wardrobe.\n",
      "Customer care\n",
      "AI is helping businesses to better understand and cater to increasing consumer demands. With the rise of highly personalized online shopping, direct-to-consumer models, and delivery services, generative AI can help further unlock a host of benefits that can improve customer care, talent transformation and the performance of applications.\n",
      "\n",
      "AI empowers businesses to adopt a customer-centric approach by harnessing valuable insights from customer feedback and buying habits. This data-driven approach can help improve product design and packaging and can help drive high customer satisfaction and increased sales.\n",
      "\n",
      "Generative AI can also serve as a cognitive assistant for customer care, providing contextual guidance based on conversation history, sentiment analysis and call center transcripts. Also, generative AI can enable personalized shopping experiences, foster customer loyalty and provide a competitive advantage.\n",
      "\n",
      "Digital labor\n",
      "Organizations can augment their workforce by building and deploying robotic process automation (RPA) and digital labor to collaborate with humans to increase productivity, or assist whenever backup is needed. For example, this can help developers speed the updating of legacy software.\n",
      "\n",
      "Digital labor uses foundation models to automate and improve the productivity of knowledge workers by enabling self-service automation in a fast and reliable way—without technical barriers. To automate task performance or calling APIs, an enterprise-grade LLM-based slot filling model can identify information in a conversation and gather all the information required for completing an action or calling an API without much manual effort.\n",
      "\n",
      "Instead of having technical experts record and encode repetitive action flows for knowledge workers, digital labor automations built with a foundation of model-powered conversational instructions and demonstrations can be used by the knowledge worker for self-service automation. For example, to speed app creation, no-code digital apprentices can help end-users, who lack programming expertise, by effectively teaching, supervising and validating code.\n",
      "\n",
      "Generative AI\n",
      "Generative AI (also called gen AI) is a category of AI that autonomously creates text, images, video, data or other content in response to a user’s prompt or request.\n",
      "\n",
      "Generative AI relies on deep learning models that can learn from patterns in existing content and generate new, similar content based on that training. It has applications in many fields—including customer service, marketing, software development and research—and offers enormous potential to streamline enterprise workflows through fast, automated content creation and augmentation.\n",
      "\n",
      "Generative AI excels at handling diverse data sources such as emails, images, videos, audio files and social media content. This unstructured data forms the backbone for creating models and the ongoing training of generative AI, so it can stay effective over time. Using this unstructured data can enhance customer service through chatbots and facilitate more effective email routing. In practice, this might mean guiding users to appropriate resources, whether that’s connecting them with the right agent or directing them to user guides and FAQs.\n",
      "\n",
      "Despite its much-discussed limitations and risks, many businesses are forging ahead, cautiously exploring how their organizations can harness generative AI to improve their internal workflows, and enhance their products and services. This is the new frontier: How to make the workplace more efficient without creating legal or ethical issues.\n",
      "\n",
      "Natural language processing and speech recognition\n",
      "NLP combines computational linguistics—rule-based modeling of human language—with statistical and machine learning models to enable computers and digital devices to recognize, understand and generate text and speech. NLP powers applications and devices that can translate text from one language to another, respond to typed or spoken commands, recognize or authenticate users based on voice. It helps summarize large volumes of text, assess the intent or sentiment of text or speech and generate text or graphics or other content on demand.\n",
      "\n",
      "A subset of NLP is statistical NLP, which combines computer algorithms with machine learning and deep learning models. This approach helps to automatically extract, classify and label elements of text and voice data and then assign a statistical likelihood to each possible meaning of those elements. Today, deep learning models and learning techniques based on RNNs enable NLP systems that “learn” as they work and extract ever more accurate meaning from huge volumes of raw, unstructured and unlabeled text and voice datasets.\n",
      "\n",
      "Speech recognition—also known as automatic speech recognition (ASR), computer speech recognition or speech-to-text—is a capability that enables a program to process human speech into a written format.\n",
      "\n",
      "While speech recognition is commonly confused with voice recognition, speech recognition focuses on the translation of speech from a verbal format to a text one whereas voice recognition just seeks to identify an individual user’s voice.\n",
      "\n",
      "Industry applications\n",
      "Real-world deep learning applications are all around us, and so well integrated into products and services that users are unaware of the complex data processing that is taking place in the background. Some of these examples include:\n",
      "\n",
      "Customer service deep learning\n",
      "Many organizations incorporate deep learning technology into their customer service processes. Chatbots are often used in various applications, services and customer service portals. Traditional chatbots use natural language and even visual recognition, commonly found in call center-like menus. However, more sophisticated chatbot solutions attempt to determine, through learning, if there are multiple responses to ambiguous questions in real time. Based on the responses it receives, the chatbot then tries to answer these questions directly or routes the conversation to a human user.\n",
      "\n",
      "Virtual assistants such as Apple's Siri, Amazon Alexa or Google Assistant extend the idea of a chatbot by enabling speech recognition functionality. This creates a new method to engage users in a personalized way.\n",
      "\n",
      "Financial services analytics\n",
      "Financial institutions regularly use predictive analytics to drive algorithmic trading of stocks, assess business risks for loan approvals, detect fraud, and help manage credit and investment portfolios for clients.\n",
      "\n",
      "Healthcare record-keeping\n",
      "The healthcare industry has benefited greatly from deep learning capabilities ever since the digitization of hospital records and images. Image recognition applications can support medical imaging specialists and radiologists, helping them analyze and assess more images in less time.\n",
      "\n",
      "Law enforcement uses deep learning\n",
      "Deep learning algorithms can analyze and learn from transactional data to identify dangerous patterns that indicate possible fraudulent or criminal activity. Speech recognition, computer vision and other deep learning applications can improve the efficiency and effectiveness of investigative analysis by extracting patterns and evidence from sound and video recordings, images and documents. This capability helps law enforcement analyze large amounts of data more quickly and accurately.\n",
      "You are an expert MCQ maker. Given the above text, it is your job to create a quiz  of 10 multiple choice questions for Deep Learning students in Intermediate tone. \n",
      "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
      "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. Ensure to make 10 MCQs\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#https://python.langchain.com/docs/modules/model_io/llms/token_usage_tracking\n",
    "\n",
    "#How to setup Token Usage Tracking in LangChain\n",
    "with get_openai_callback() as cb:\n",
    "    response=generate_evaluate_chain(\n",
    "        {\n",
    "            \"text\": TEXT,\n",
    "            \"number\": NUMBER,\n",
    "            \"subject\":SUBJECT,\n",
    "            \"tone\": TONE,\n",
    "            \"response_json\": json.dumps(RESPONSE_JSON)\n",
    "        }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens:12995\n",
      "Prompt Tokens:11218\n",
      "Completion Tokens:1777\n",
      "Total Cost:0.045815\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Tokens:{cb.total_tokens}\")\n",
    "print(f\"Prompt Tokens:{cb.prompt_tokens}\")\n",
    "print(f\"Completion Tokens:{cb.completion_tokens}\")\n",
    "print(f\"Total Cost:{cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'What is deep learning?\\nDeep learning is a subset of machine learning that uses multilayered neural networks, called deep neural networks, to simulate the complex decision-making power of the human brain. Some form of deep learning powers most of the artificial intelligence (AI) applications in our lives today.\\n\\nThe chief difference between deep learning and machine learning is the structure of the underlying neural network architecture. “Nondeep,” traditional machine learning models use simple neural networks with one or two computational layers. Deep learning models use three or more layers—but typically hundreds or thousands of layers—to train the models.\\n\\nWhile supervised learning models require structured, labeled input data to make accurate outputs, deep learning models can use unsupervised learning. With unsupervised learning, deep learning models can extract the characteristics, features and relationships they need to make accurate outputs from raw, unstructured data. Additionally, these models can even evaluate and refine their outputs for increased precision.\\n\\nDeep learning is an aspect of data science that drives many applications and services that improve automation, performing analytical and physical tasks without human intervention. This enables many everyday products and services—such as digital assistants, voice-enabled TV remotes, credit card fraud detection, self-driving cars and generative AI.\\n\\n3D design of balls rolling on a track\\nThe latest AI News + Insights \\nDiscover expertly curated insights and news on AI, cloud and more in the weekly Think Newsletter. \\n\\nSubscribe today\\nHow deep learning works\\nNeural networks, or artificial neural networks, attempt to mimic the human brain through a combination of data inputs, weights and bias—all acting as silicon neurons. These elements work together to accurately recognize, classify and describe objects within the data.\\n\\nDeep neural networks consist of multiple layers of interconnected nodes, each building on the previous layer to refine and optimize the prediction or categorization. This progression of computations through the network is called forward propagation. The input and output layers of a deep neural network are called visible layers. The input layer is where the deep learning model ingests the data for processing, and the output layer is where the final prediction or classification is made.\\n\\nAnother process called backpropagation uses algorithms, such as gradient descent, to calculate errors in predictions, and then adjusts the weights and biases of the function by moving backwards through the layers to train the model. Together, forward propagation and backpropagation enable a neural network to make predictions and correct for any errors. Over time, the algorithm becomes gradually more accurate.\\n\\nDeep learning requires a tremendous amount of computing power. High-performance graphical processing units (GPUs) are ideal because they can handle a large volume of calculations in multiple cores with copious memory available. Distributed cloud computing might also assist. This level of computing power is necessary to train deep algorithms through deep learning. However, managing multiple GPUs on premises can create a large demand on internal resources and be incredibly costly to scale. For software requirements, most deep learning apps are coded with one of these three learning frameworks: JAX, PyTorch or TensorFlow.\\n\\nMixture of Experts | 14 February, episode 42\\n\\nEpisode 42: Paris AI Summit, Altman\\'s \"Three Observations,\" Anthropic\\'s Economic Index\\nDecoding AI: Weekly News Roundup\\nJoin our world-class panel of engineers, researchers, product leaders and more as they cut through the AI noise to bring you the latest in AI news and insights.\\n\\nWatch the latest podcast episodes \\nTypes of deep learning models\\nDeep learning algorithms are incredibly complex, and there are different types of neural networks to address specific problems or datasets. Here are six. Each has its own advantages and they are presented here roughly in the order of their development, with each successive model adjusting to overcome a weakness in a previous model.\\n\\nOne potential weakness across them all is that deep learning models are often “black boxes,” making it difficult to understand their inner workings and posing interpretability challenges. But this can be balanced against the overall benefits of high accuracy and scalability.\\n\\nCNNs\\nConvolutional neural networks (CNNs or ConvNets) are used primarily in computer vision and image classification applications. They can detect features and patterns within images and videos, enabling tasks such as object detection, image recognition, pattern recognition and face recognition. These networks harness principles from linear algebra, particularly matrix multiplication, to identify patterns within an image.\\n\\nCNNs are a specific type of neural network, which is composed of node layers, containing an input layer, one or more hidden layers and an output layer. Each node connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network.\\n\\nAt least three main types of layers make up a CNN: a convolutional layer, pooling layer and fully connected (FC) layer. For complex uses, a CNN might contain up to thousands of layers, each layer building on the previous layers. By “convolution”—working and reworking the original input—detailed patterns can be discovered. With each layer, the CNN increases in its complexity, identifying greater portions of the image. Earlier layers focus on simple features, such as colors and edges. As the image data progresses through the layers of the CNN, it starts to recognize larger elements or shapes of the object until it finally identifies the intended object.\\n\\nCNNs are distinguished from other neural networks by their superior performance with image, speech or audio signal inputs. Before CNNs, manual and time-consuming feature extraction methods were used to identify objects in images. However, CNNs now provide a more scalable approach to image classification and object recognition tasks, and process high-dimensional data. And CNNs can exchange data between layers, to deliver more efficient data processing. While information might be lost in the pooling layer, this might be outweighed by the benefits of CNNs, which can help to reduce complexity, improve efficiency and limit risk of overfitting.\\n\\nThere are other disadvantages to CNNs, which are computationally demanding—costing time and budget, requiring many graphical processing units (GPUs). They also require highly trained experts with cross-domain knowledge, and careful testing of configurations, hyperparameters and configurations.\\n\\nRNNs\\nRecurrent neural networks (RNNs) are typically used in natural language and speech recognition applications as they use sequential or time-series data. RNNs can be identified by their feedback loops. These learning algorithms are primarily used when using time-series data to make predictions about future outcomes. Use cases include stock market predictions or sales forecasting, or ordinal or temporal problems, such as language translation, natural language processing (NLP), speech recognition and image captioning. These functions are often incorporated into popular applications such as Siri, voice search and Google Translate.\\n\\nRNNs use their “memory” as they take information from prior inputs to influence the current input and output. While traditional deep neural networks assume that inputs and outputs are independent of each other, the output of RNNs depends on the prior elements within the sequence. While future events would also be helpful in determining the output of a given sequence, unidirectional recurrent neural networks cannot account for these events in their predictions.\\n\\nRNNs share parameters across each layer of the network and share the same weight parameter within each layer of the network, with the weights adjusted through the processes of backpropagation and gradient descent to facilitate reinforcement learning.\\n\\nRNNs use a backpropagation through time (BPTT) algorithm to determine the gradients, which is slightly different from traditional backpropagation as it is specific to sequence data. The principles of BPTT are the same as traditional backpropagation, where the model trains itself by calculating errors from its output layer to its input layer. BPTT differs from the traditional approach in that BPTT sums errors at each time step, whereas feedforward networks do not need to sum errors as they do not share parameters across each layer.\\n\\nAn advantage over other neural network types is that RNNs use both binary data processing and memory. RNNs can plan out multiple inputs and productions so that rather than delivering only one result for a single input, RNNs can produce one-to-many, many-to-one or many-to-many outputs.\\n\\nThere are also options within RNNs. For example, the long short-term memory (LSTM) network is superior to simple RNNs by learning and acting on longer-term dependencies.\\n\\nHowever, RNNs tend to run into two basic problems, known as exploding gradients and vanishing gradients. These issues are defined by the size of the gradient, which is the slope of the loss function along the error curve.\\n\\nWhen the gradient is vanishing and is too small, it continues to become smaller, updating the weight parameters until they become insignificant—that is: zero (0). When that occurs, the algorithm is no longer learning.\\nExploding gradients occur when the gradient is too large, creating an unstable model. In this case, the model weights grow too large, and they will eventually be represented as NaN (not a number). One solution to these issues is to reduce the number of hidden layers within the neural network, eliminating some of the complexity in the RNN models.\\nSome final disadvantages: RNNs might also require long training time and be difficult to use on large datasets. Optimizing RNNs add complexity when they have many layers and parameters.\\n\\nAutoencoders and variational autoencoders\\nDeep learning made it possible to move beyond the analysis of numerical data, by adding the analysis of images, speech and other complex data types. Among the first class of models to achieve this were variational autoencoders (VAEs). They were the first deep-learning models to be widely used for generating realistic images and speech, which empowered deep generative modeling by making models easier to scale—which is the cornerstone of what we think of as generative AI.\\n\\nAutoencoders work by encoding unlabeled data into a compressed representation, and then decoding the data back into its original form. Plain autoencoders were used for a variety of purposes, including reconstructing corrupted or blurry images. Variational autoencoders added the critical ability not just to reconstruct data, but also to output variations on the original data.\\n\\nThis ability to generate novel data ignited a rapid-fire succession of new technologies, from generative adversarial networks (GANs) to diffusion models, capable of producing ever more realistic—but fake—images. In this way, VAEs set the stage for today’s generative AI.\\n\\nAutoencoders are built out of blocks of encoders and decoders, an architecture that also underpins today’s large language models. Encoders compress a dataset into a dense representation, arranging similar data points closer together in an abstract space. Decoders sample from this space to create something new while preserving the dataset’s most important features.\\n\\nThe biggest advantage to autoencoders is the ability to handle large batches of data and show input data in a compressed form, so the most significant aspects stand out—enabling anomaly detection and classification tasks. This also speeds transmission and reduces storage requirements. Autoencoders can be trained on unlabeled data so they might be used where labeled data is not available. When unsupervised training is used, there is a time savings advantage: deep learning algorithms learn automatically and gain accuracy without needing manual feature engineering. In addition, VAEs can generate new sample data for text or image generation.\\n\\nThere are disadvantages to autoencoders. The training of deep or intricate structures can be a drain on computational resources. And during unsupervised training, the model might overlook the needed properties and instead simply replicate the input data. Autoencoders might also overlook complex data linkages in structured data so that it does not correctly identify complex relationships.\\n\\nGANs\\nGenerative adversarial networks (GANs) are neural networks that are used both in and outside of artificial intelligence (AI) to create new data resembling the original training data. These can include images appearing to be human faces—but are generated, not taken of real people. The “adversarial” part of the name comes from the back-and-forth between the two portions of the GAN: a generator and a discriminator.\\n\\nThe generator creates something: images, video or audio and then producing an output with a twist. For example, a horse can be transformed into a zebra with some degree of accuracy. The result depends on the input and how well-trained the layers are in the generative model for this use case.\\nThe discriminator is the adversary, where the generative result (fake image) is compared against the real images in the dataset. The discriminator tries to distinguish between the real and fake images, video or audio.\\nGANs train themselves. The generator creates fakes while the discriminator learns to spot the differences between the generator\\'s fakes and the true examples. When the discriminator is able to flag the fake, then the generator is penalized. The feedback loop continues until the generator succeeds in producing output that the discriminator cannot distinguish.\\n\\nThe prime GAN benefit is creating realistic output that can be difficult to distinguish from the originals, which in turn may be used to further train machine learning models. Setting up a GAN to learn is straightforward, since they are trained by using unlabeled data or with minor labeling. However, the potential disadvantage is that the generator and discriminator might go back-and-forth in competition for a long time, creating a large system drain. One training limitation is that a huge amount of input data might be required to obtain a satisfactory output. Another potential problem is “mode collapse,” when the generator produces a limited set of outputs rather than a wider variety.\\n\\nDiffusion models\\nDiffusion models are generative models that are trained using the forward and reverse diffusion process of progressive noise-addition and denoising. Diffusion models generate data—most often images—similar to the data on which they are trained, but then overwrite the data used to train them. They gradually add Gaussian noise to the training data until it’s unrecognizable, then learn a reversed “denoising” process that can synthesize output (usually images) from random noise input.\\n\\nA diffusion model learns to minimize the differences of the generated samples versus the desired target. Any discrepancy is quantified and the model\\'s parameters are updated to minimize the loss—training the model to produce samples closely resembling the authentic training data.\\n\\nBeyond image quality, diffusion models have the advantage of not requiring adversarial training, which speeds the learning process and also offering close process control. Training is more stable than with GANs and diffusion models are not as prone to mode collapse.\\n\\nBut, compared to GANs, diffusion models can require more computing resources to train, including more fine-tuning. IBM Research® has also discovered that this form of generative AI can be hijacked with hidden backdoors, giving attackers control over the image creation process so that AI diffusion models can be tricked into generating manipulated images.\\n\\nTransformer models\\nTransformer models combine an encoder-decoder architecture with a text-processing mechanism and have revolutionized how language models are trained. An encoder converts raw, unannotated text into representations known as embeddings; the decoder takes these embeddings together with previous outputs of the model, and successively predicts each word in a sentence.\\n\\nUsing fill-in-the-blank guessing, the encoder learns how words and sentences relate to each other, building up a powerful representation of language without having to label parts of speech and other grammatical features. Transformers, in fact, can be pretrained at the outset without a particular task in mind. After these powerful representations are learned, the models can later be specialized—with much less data—to perform a requested task.\\n\\nSeveral innovations make this possible. Transformers process words in a sentence simultaneously, enabling text processing in parallel, speeding up training. Earlier techniques including recurrent neural networks (RNNs) processed words one by one. Transformers also learned the positions of words and their relationships—this context enables them to infer meaning and disambiguate words such as “it” in long sentences.\\n\\nBy eliminating the need to define a task upfront, transformers made it practical to pretrain language models on vast amounts of raw text, enabling them to grow dramatically in size. Previously, labeled data was gathered to train one model on a specific task. With transformers, one model trained on a massive amount of data can be adapted to multiple tasks by fine-tuning it on a small amount of labeled task-specific data.\\n\\nLanguage transformers today are used for nongenerative tasks such as classification and entity extraction as well as generative tasks including machine translation, summarization and question answering. Transformers have surprised many people with their ability to generate convincing dialog, essays and other content.\\n\\nNatural language processing (NLP) transformers provide remarkable power since they can run in parallel, processing multiple portions of a sequence simultaneously, which then greatly speeds training. Transformers also track long-term dependencies in text, which enables them to understand the overall context more clearly and create superior output. In addition, transformers are more scalable and flexible in order to be customized by task.\\n\\nAs to limitations, because of their complexity, transformers require huge computational resources and a long training time. Also, the training data must be accurately on-target, unbiased and plentiful to produce accurate results.\\n\\nDeep learning use cases\\nThe number of uses for deep learning grows every day. Here are just a few of the ways that it is now helping businesses become more efficient and better serve their customers.\\n\\nApplication modernization\\nGenerative AI can enhance the capabilities of developers and reduce the ever-widening skills gap in the domains of application modernization and IT automation. Generative AI for coding is possible because of recent breakthroughs in large language model (LLM) technologies and natural language processing (NLP). It uses deep learning algorithms and large neural networks trained on vast datasets of existing source code. Training code generally comes from publicly available code produced by open-source projects.\\n\\nProgrammers can enter plain text prompts describing what they want the code to do. Generative AI tools suggest code snippets or full functions, streamlining the coding process by handling repetitive tasks and reducing manual coding. Generative AI can also translate code from one language to another, streamlining code conversion or modernization projects, such as updating legacy applications by translating COBOL to Java.\\n\\nComputer vision\\nComputer vision is a field of artificial intelligence (AI) that includes image classification, object detection and semantic segmentation. It uses machine learning and neural networks to teach computers and learning systems to derive meaningful information from digital images, videos and other visual inputs—and to make recommendations or take actions when the system sees defects or issues. If AI enables computers to think, computer vision enables them to see, observe and understand.\\n\\nBecause a computer vision system is often trained to inspect products or watch production assets, it usually can analyze thousands of products or processes per minute, noticing imperceptible defects or issues. Computer vision is used in industries that range from energy and utilities to manufacturing and automotive.\\n\\nComputer vision needs lots of data, and then it runs analyses of that data over and over until it discerns and ultimately recognizes images. For example, to train a computer to recognize automobile tires, it needs to be fed vast quantities of tire images and tire-related items to learn the differences and recognize a tire, especially one with no defects.\\n\\nComputer vision uses algorithmic models to enable a computer to teach itself about the context of visual data. If enough data is fed through the model, the computer will “look” at the data and teach itself to tell one image from another. Algorithms enable the machine to learn by itself, rather than with someone programming it to recognize an image.\\n\\nComputer vision enables systems to derive meaningful information from digital images, videos and other visual inputs, and based on those inputs, to take action. This ability to provide recommendations distinguishes it from simple image recognition tasks. Some common applications of computer vision today can be seen in:\\n\\nAutomotive: While the age of driverless cars hasn’t entirely arrived, the underlying technology has started to make its way into automobiles, improving driver and passenger safety through features such as lane line detection.\\n\\nHealthcare: Computer vision has been incorporated into radiology technology, enabling doctors to better identify cancerous tumors in healthy anatomy.\\n\\nMarketing: Social media platforms provide suggestions on who might be in a photograph that has been posted on a profile, making it easier to tag friends in photo albums.\\n\\nRetail: Visual search has been incorporated into some e-commerce platforms, enabling brands to recommend items that would complement an existing wardrobe.\\nCustomer care\\nAI is helping businesses to better understand and cater to increasing consumer demands. With the rise of highly personalized online shopping, direct-to-consumer models, and delivery services, generative AI can help further unlock a host of benefits that can improve customer care, talent transformation and the performance of applications.\\n\\nAI empowers businesses to adopt a customer-centric approach by harnessing valuable insights from customer feedback and buying habits. This data-driven approach can help improve product design and packaging and can help drive high customer satisfaction and increased sales.\\n\\nGenerative AI can also serve as a cognitive assistant for customer care, providing contextual guidance based on conversation history, sentiment analysis and call center transcripts. Also, generative AI can enable personalized shopping experiences, foster customer loyalty and provide a competitive advantage.\\n\\nDigital labor\\nOrganizations can augment their workforce by building and deploying robotic process automation (RPA) and digital labor to collaborate with humans to increase productivity, or assist whenever backup is needed. For example, this can help developers speed the updating of legacy software.\\n\\nDigital labor uses foundation models to automate and improve the productivity of knowledge workers by enabling self-service automation in a fast and reliable way—without technical barriers. To automate task performance or calling APIs, an enterprise-grade LLM-based slot filling model can identify information in a conversation and gather all the information required for completing an action or calling an API without much manual effort.\\n\\nInstead of having technical experts record and encode repetitive action flows for knowledge workers, digital labor automations built with a foundation of model-powered conversational instructions and demonstrations can be used by the knowledge worker for self-service automation. For example, to speed app creation, no-code digital apprentices can help end-users, who lack programming expertise, by effectively teaching, supervising and validating code.\\n\\nGenerative AI\\nGenerative AI (also called gen AI) is a category of AI that autonomously creates text, images, video, data or other content in response to a user’s prompt or request.\\n\\nGenerative AI relies on deep learning models that can learn from patterns in existing content and generate new, similar content based on that training. It has applications in many fields—including customer service, marketing, software development and research—and offers enormous potential to streamline enterprise workflows through fast, automated content creation and augmentation.\\n\\nGenerative AI excels at handling diverse data sources such as emails, images, videos, audio files and social media content. This unstructured data forms the backbone for creating models and the ongoing training of generative AI, so it can stay effective over time. Using this unstructured data can enhance customer service through chatbots and facilitate more effective email routing. In practice, this might mean guiding users to appropriate resources, whether that’s connecting them with the right agent or directing them to user guides and FAQs.\\n\\nDespite its much-discussed limitations and risks, many businesses are forging ahead, cautiously exploring how their organizations can harness generative AI to improve their internal workflows, and enhance their products and services. This is the new frontier: How to make the workplace more efficient without creating legal or ethical issues.\\n\\nNatural language processing and speech recognition\\nNLP combines computational linguistics—rule-based modeling of human language—with statistical and machine learning models to enable computers and digital devices to recognize, understand and generate text and speech. NLP powers applications and devices that can translate text from one language to another, respond to typed or spoken commands, recognize or authenticate users based on voice. It helps summarize large volumes of text, assess the intent or sentiment of text or speech and generate text or graphics or other content on demand.\\n\\nA subset of NLP is statistical NLP, which combines computer algorithms with machine learning and deep learning models. This approach helps to automatically extract, classify and label elements of text and voice data and then assign a statistical likelihood to each possible meaning of those elements. Today, deep learning models and learning techniques based on RNNs enable NLP systems that “learn” as they work and extract ever more accurate meaning from huge volumes of raw, unstructured and unlabeled text and voice datasets.\\n\\nSpeech recognition—also known as automatic speech recognition (ASR), computer speech recognition or speech-to-text—is a capability that enables a program to process human speech into a written format.\\n\\nWhile speech recognition is commonly confused with voice recognition, speech recognition focuses on the translation of speech from a verbal format to a text one whereas voice recognition just seeks to identify an individual user’s voice.\\n\\nIndustry applications\\nReal-world deep learning applications are all around us, and so well integrated into products and services that users are unaware of the complex data processing that is taking place in the background. Some of these examples include:\\n\\nCustomer service deep learning\\nMany organizations incorporate deep learning technology into their customer service processes. Chatbots are often used in various applications, services and customer service portals. Traditional chatbots use natural language and even visual recognition, commonly found in call center-like menus. However, more sophisticated chatbot solutions attempt to determine, through learning, if there are multiple responses to ambiguous questions in real time. Based on the responses it receives, the chatbot then tries to answer these questions directly or routes the conversation to a human user.\\n\\nVirtual assistants such as Apple\\'s Siri, Amazon Alexa or Google Assistant extend the idea of a chatbot by enabling speech recognition functionality. This creates a new method to engage users in a personalized way.\\n\\nFinancial services analytics\\nFinancial institutions regularly use predictive analytics to drive algorithmic trading of stocks, assess business risks for loan approvals, detect fraud, and help manage credit and investment portfolios for clients.\\n\\nHealthcare record-keeping\\nThe healthcare industry has benefited greatly from deep learning capabilities ever since the digitization of hospital records and images. Image recognition applications can support medical imaging specialists and radiologists, helping them analyze and assess more images in less time.\\n\\nLaw enforcement uses deep learning\\nDeep learning algorithms can analyze and learn from transactional data to identify dangerous patterns that indicate possible fraudulent or criminal activity. Speech recognition, computer vision and other deep learning applications can improve the efficiency and effectiveness of investigative analysis by extracting patterns and evidence from sound and video recordings, images and documents. This capability helps law enforcement analyze large amounts of data more quickly and accurately.',\n",
       " 'number': 10,\n",
       " 'subject': 'Deep Learning',\n",
       " 'tone': 'Intermediate',\n",
       " 'response_json': '{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}',\n",
       " 'quiz': '```json\\n{\\n    \"1\": {\\n        \"mcq\": \"What is the primary difference between deep learning and traditional machine learning?\",\\n        \"options\": {\\n            \"a\": \"Deep learning uses simple neural networks.\",\\n            \"b\": \"Deep learning can only use supervised learning.\",\\n            \"c\": \"Deep learning models use three or more layers.\",\\n            \"d\": \"Deep learning models require labeled data.\"\\n        },\\n        \"correct\": \"c\"\\n    },\\n    \"2\": {\\n        \"mcq\": \"Which of the following frameworks is NOT typically used for deep learning applications?\",\\n        \"options\": {\\n            \"a\": \"PyTorch\",\\n            \"b\": \"TensorFlow\",\\n            \"c\": \"JAX\",\\n            \"d\": \"Java\"\\n        },\\n        \"correct\": \"d\"\\n    },\\n    \"3\": {\\n        \"mcq\": \"What type of neural network is primarily used for image classification tasks?\",\\n        \"options\": {\\n            \"a\": \"Recurrent Neural Networks (RNNs)\",\\n            \"b\": \"Convolutional Neural Networks (CNNs)\",\\n            \"c\": \"Autoencoders\",\\n            \"d\": \"Transformer models\"\\n        },\\n        \"correct\": \"b\"\\n    },\\n    \"4\": {\\n        \"mcq\": \"What is a common disadvantage of Recurrent Neural Networks (RNNs)?\",\\n        \"options\": {\\n            \"a\": \"They require labeled data.\",\\n            \"b\": \"They have a high risk of overfitting.\",\\n            \"c\": \"They are prone to vanishing and exploding gradients.\",\\n            \"d\": \"They are not suitable for sequence data.\"\\n        },\\n        \"correct\": \"c\"\\n    },\\n    \"5\": {\\n        \"mcq\": \"Which deep learning model is known for its encoder-decoder architecture?\",\\n        \"options\": {\\n            \"a\": \"Convolutional Neural Networks (CNNs)\",\\n            \"b\": \"Generative Adversarial Networks (GANs)\",\\n            \"c\": \"Transformer models\",\\n            \"d\": \"Variational Autoencoders (VAEs)\"\\n        },\\n        \"correct\": \"c\"\\n    },\\n    \"6\": {\\n        \"mcq\": \"What is the main advantage of using Generative Adversarial Networks (GANs)?\",\\n        \"options\": {\\n            \"a\": \"They are easy to interpret.\",\\n            \"b\": \"They require minimal computational resources.\",\\n            \"c\": \"They can create realistic outputs resembling real data.\",\\n            \"d\": \"They do not require labeled data.\"\\n        },\\n        \"correct\": \"c\"\\n    },\\n    \"7\": {\\n        \"mcq\": \"Which of the following is a key feature of diffusion models?\",\\n        \"options\": {\\n            \"a\": \"They use adversarial training.\",\\n            \"b\": \"They add Gaussian noise to training data.\",\\n            \"c\": \"They primarily work with text data.\",\\n            \"d\": \"They are prone to mode collapse.\"\\n        },\\n        \"correct\": \"b\"\\n    },\\n    \"8\": {\\n        \"mcq\": \"What is one potential weakness of deep learning models?\",\\n        \"options\": {\\n            \"a\": \"They are easily interpretable.\",\\n            \"b\": \"They require structured data.\",\\n            \"c\": \"They can be \\'black boxes\\' with interpretability challenges.\",\\n            \"d\": \"They are not scalable.\"\\n        },\\n        \"correct\": \"c\"\\n    },\\n    \"9\": {\\n        \"mcq\": \"In what area is computer vision NOT commonly used?\",\\n        \"options\": {\\n            \"a\": \"Automotive industry\",\\n            \"b\": \"Healthcare\",\\n            \"c\": \"Retail\",\\n            \"d\": \"Cooking\"\\n        },\\n        \"correct\": \"d\"\\n    },\\n    \"10\": {\\n        \"mcq\": \"What is a significant advantage of using autoencoders?\",\\n        \"options\": {\\n            \"a\": \"They require labeled data.\",\\n            \"b\": \"They can compress data for anomaly detection.\",\\n            \"c\": \"They are easy to train.\",\\n            \"d\": \"They are only used for image data.\"\\n        },\\n        \"correct\": \"b\"\\n    }\\n}\\n```',\n",
       " 'review': '```json\\n{\\n  \"1\": {\\n    \"mcq\": \"What is the primary difference between deep learning and traditional machine learning models?\",\\n    \"options\": {\\n      \"a\": \"Deep learning uses simple neural networks with one or two layers.\",\\n      \"b\": \"Traditional machine learning models use unsupervised learning.\",\\n      \"c\": \"Deep learning models typically have hundreds or thousands of layers.\",\\n      \"d\": \"Traditional machine learning models require high-performance GPUs.\"\\n    },\\n    \"correct\": \"c\"\\n  },\\n  \"2\": {\\n    \"mcq\": \"Which of the following frameworks is commonly used for deep learning applications?\",\\n    \"options\": {\\n      \"a\": \"JAX\",\\n      \"b\": \"PyTorch\",\\n      \"c\": \"TensorFlow\",\\n      \"d\": \"All of the above\"\\n    },\\n    \"correct\": \"d\"\\n  },\\n  \"3\": {\\n    \"mcq\": \"Which type of neural network is primarily used for image classification and computer vision tasks?\",\\n    \"options\": {\\n      \"a\": \"Recurrent Neural Networks (RNNs)\",\\n      \"b\": \"Convolutional Neural Networks (CNNs)\",\\n      \"c\": \"Variational Autoencoders (VAEs)\",\\n      \"d\": \"Transformer Models\"\\n    },\\n    \"correct\": \"b\"\\n  },\\n  \"4\": {\\n    \"mcq\": \"What is the main advantage of using Recurrent Neural Networks (RNNs)?\",\\n    \"options\": {\\n      \"a\": \"They have no vanishing gradient issues.\",\\n      \"b\": \"They are ideal for image recognition tasks.\",\\n      \"c\": \"They can handle sequential or time-series data.\",\\n      \"d\": \"They require less training time compared to other models.\"\\n    },\\n    \"correct\": \"c\"\\n  },\\n  \"5\": {\\n    \"mcq\": \"What is the primary function of the discriminator in a Generative Adversarial Network (GAN)?\",\\n    \"options\": {\\n      \"a\": \"To generate new data resembling the training data.\",\\n      \"b\": \"To transform input data into a compressed representation.\",\\n      \"c\": \"To distinguish between real and fake data.\",\\n      \"d\": \"To add noise to the training data.\"\\n    },\\n    \"correct\": \"c\"\\n  },\\n  \"6\": {\\n    \"mcq\": \"Which of the following is a key feature of Transformer models?\",\\n    \"options\": {\\n      \"a\": \"They process words one by one.\",\\n      \"b\": \"They require labeled data for training.\",\\n      \"c\": \"They can process words in parallel.\",\\n      \"d\": \"They are only used for image processing tasks.\"\\n    },\\n    \"correct\": \"c\"\\n  },\\n  \"7\": {\\n    \"mcq\": \"What is a major challenge associated with deep learning models?\",\\n    \"options\": {\\n      \"a\": \"They are always easy to interpret.\",\\n      \"b\": \"They require minimal computational resources.\",\\n      \"c\": \"They often function as \\'black boxes\\'.\",\\n      \"d\": \"They cannot handle unstructured data.\"\\n    },\\n    \"correct\": \"c\"\\n  },\\n  \"8\": {\\n    \"mcq\": \"Which deep learning model is known for its ability to generate novel data?\",\\n    \"options\": {\\n      \"a\": \"Convolutional Neural Networks (CNNs)\",\\n      \"b\": \"Autoencoders\",\\n      \"c\": \"Recurrent Neural Networks (RNNs)\",\\n      \"d\": \"Diffusion Models\"\\n    },\\n    \"correct\": \"b\"\\n  },\\n  \"9\": {\\n    \"mcq\": \"What does backpropagation in a neural network achieve?\",\\n    \"options\": {\\n      \"a\": \"It initializes the weights and biases.\",\\n      \"b\": \"It calculates errors and adjusts the weights and biases.\",\\n      \"c\": \"It processes input data for prediction.\",\\n      \"d\": \"It increases the number of layers in the network.\"\\n    },\\n    \"correct\": \"b\"\\n  },\\n  \"10\": {\\n    \"mcq\": \"What is a common application of deep learning in the healthcare industry?\",\\n    \"options\": {\\n      \"a\": \"Predictive analytics for stock trading\",\\n      \"b\": \"Analyzing and assessing medical images\",\\n      \"c\": \"Real-time language translation\",\\n      \"d\": \"Automating customer service chatbots\"\\n    },\\n    \"correct\": \"b\"\\n  }\\n}\\n```'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=response.get(\"quiz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'```json\\n{\\n    \"1\": {\\n        \"mcq\": \"What is the primary difference between deep learning and traditional machine learning?\",\\n        \"options\": {\\n            \"a\": \"Deep learning uses simple neural networks.\",\\n            \"b\": \"Deep learning can only use supervised learning.\",\\n            \"c\": \"Deep learning models use three or more layers.\",\\n            \"d\": \"Deep learning models require labeled data.\"\\n        },\\n        \"correct\": \"c\"\\n    },\\n    \"2\": {\\n        \"mcq\": \"Which of the following frameworks is NOT typically used for deep learning applications?\",\\n        \"options\": {\\n            \"a\": \"PyTorch\",\\n            \"b\": \"TensorFlow\",\\n            \"c\": \"JAX\",\\n            \"d\": \"Java\"\\n        },\\n        \"correct\": \"d\"\\n    },\\n    \"3\": {\\n        \"mcq\": \"What type of neural network is primarily used for image classification tasks?\",\\n        \"options\": {\\n            \"a\": \"Recurrent Neural Networks (RNNs)\",\\n            \"b\": \"Convolutional Neural Networks (CNNs)\",\\n            \"c\": \"Autoencoders\",\\n            \"d\": \"Transformer models\"\\n        },\\n        \"correct\": \"b\"\\n    },\\n    \"4\": {\\n        \"mcq\": \"What is a common disadvantage of Recurrent Neural Networks (RNNs)?\",\\n        \"options\": {\\n            \"a\": \"They require labeled data.\",\\n            \"b\": \"They have a high risk of overfitting.\",\\n            \"c\": \"They are prone to vanishing and exploding gradients.\",\\n            \"d\": \"They are not suitable for sequence data.\"\\n        },\\n        \"correct\": \"c\"\\n    },\\n    \"5\": {\\n        \"mcq\": \"Which deep learning model is known for its encoder-decoder architecture?\",\\n        \"options\": {\\n            \"a\": \"Convolutional Neural Networks (CNNs)\",\\n            \"b\": \"Generative Adversarial Networks (GANs)\",\\n            \"c\": \"Transformer models\",\\n            \"d\": \"Variational Autoencoders (VAEs)\"\\n        },\\n        \"correct\": \"c\"\\n    },\\n    \"6\": {\\n        \"mcq\": \"What is the main advantage of using Generative Adversarial Networks (GANs)?\",\\n        \"options\": {\\n            \"a\": \"They are easy to interpret.\",\\n            \"b\": \"They require minimal computational resources.\",\\n            \"c\": \"They can create realistic outputs resembling real data.\",\\n            \"d\": \"They do not require labeled data.\"\\n        },\\n        \"correct\": \"c\"\\n    },\\n    \"7\": {\\n        \"mcq\": \"Which of the following is a key feature of diffusion models?\",\\n        \"options\": {\\n            \"a\": \"They use adversarial training.\",\\n            \"b\": \"They add Gaussian noise to training data.\",\\n            \"c\": \"They primarily work with text data.\",\\n            \"d\": \"They are prone to mode collapse.\"\\n        },\\n        \"correct\": \"b\"\\n    },\\n    \"8\": {\\n        \"mcq\": \"What is one potential weakness of deep learning models?\",\\n        \"options\": {\\n            \"a\": \"They are easily interpretable.\",\\n            \"b\": \"They require structured data.\",\\n            \"c\": \"They can be \\'black boxes\\' with interpretability challenges.\",\\n            \"d\": \"They are not scalable.\"\\n        },\\n        \"correct\": \"c\"\\n    },\\n    \"9\": {\\n        \"mcq\": \"In what area is computer vision NOT commonly used?\",\\n        \"options\": {\\n            \"a\": \"Automotive industry\",\\n            \"b\": \"Healthcare\",\\n            \"c\": \"Retail\",\\n            \"d\": \"Cooking\"\\n        },\\n        \"correct\": \"d\"\\n    },\\n    \"10\": {\\n        \"mcq\": \"What is a significant advantage of using autoencoders?\",\\n        \"options\": {\\n            \"a\": \"They require labeled data.\",\\n            \"b\": \"They can compress data for anomaly detection.\",\\n            \"c\": \"They are easy to train.\",\\n            \"d\": \"They are only used for image data.\"\\n        },\\n        \"correct\": \"b\"\\n    }\\n}\\n```'\n"
     ]
    }
   ],
   "source": [
    "print(repr(quiz))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'{\\n    \"1\": {\\n        \"mcq\": \"What is the primary difference between deep learning and traditional machine learning?\",\\n        \"options\": {\\n            \"a\": \"Deep learning uses simple neural networks.\",\\n            \"b\": \"Deep learning can only use supervised learning.\",\\n            \"c\": \"Deep learning models use three or more layers.\",\\n            \"d\": \"Deep learning models require labeled data.\"\\n        },\\n        \"correct\": \"c\"\\n    },\\n    \"2\": {\\n        \"mcq\": \"Which of the following frameworks is NOT typically used for deep learning applications?\",\\n        \"options\": {\\n            \"a\": \"PyTorch\",\\n            \"b\": \"TensorFlow\",\\n            \"c\": \"JAX\",\\n            \"d\": \"Java\"\\n        },\\n        \"correct\": \"d\"\\n    },\\n    \"3\": {\\n        \"mcq\": \"What type of neural network is primarily used for image classification tasks?\",\\n        \"options\": {\\n            \"a\": \"Recurrent Neural Networks (RNNs)\",\\n            \"b\": \"Convolutional Neural Networks (CNNs)\",\\n            \"c\": \"Autoencoders\",\\n            \"d\": \"Transformer models\"\\n        },\\n        \"correct\": \"b\"\\n    },\\n    \"4\": {\\n        \"mcq\": \"What is a common disadvantage of Recurrent Neural Networks (RNNs)?\",\\n        \"options\": {\\n            \"a\": \"They require labeled data.\",\\n            \"b\": \"They have a high risk of overfitting.\",\\n            \"c\": \"They are prone to vanishing and exploding gradients.\",\\n            \"d\": \"They are not suitable for sequence data.\"\\n        },\\n        \"correct\": \"c\"\\n    },\\n    \"5\": {\\n        \"mcq\": \"Which deep learning model is known for its encoder-decoder architecture?\",\\n        \"options\": {\\n            \"a\": \"Convolutional Neural Networks (CNNs)\",\\n            \"b\": \"Generative Adversarial Networks (GANs)\",\\n            \"c\": \"Transformer models\",\\n            \"d\": \"Variational Autoencoders (VAEs)\"\\n        },\\n        \"correct\": \"c\"\\n    },\\n    \"6\": {\\n        \"mcq\": \"What is the main advantage of using Generative Adversarial Networks (GANs)?\",\\n        \"options\": {\\n            \"a\": \"They are easy to interpret.\",\\n            \"b\": \"They require minimal computational resources.\",\\n            \"c\": \"They can create realistic outputs resembling real data.\",\\n            \"d\": \"They do not require labeled data.\"\\n        },\\n        \"correct\": \"c\"\\n    },\\n    \"7\": {\\n        \"mcq\": \"Which of the following is a key feature of diffusion models?\",\\n        \"options\": {\\n            \"a\": \"They use adversarial training.\",\\n            \"b\": \"They add Gaussian noise to training data.\",\\n            \"c\": \"They primarily work with text data.\",\\n            \"d\": \"They are prone to mode collapse.\"\\n        },\\n        \"correct\": \"b\"\\n    },\\n    \"8\": {\\n        \"mcq\": \"What is one potential weakness of deep learning models?\",\\n        \"options\": {\\n            \"a\": \"They are easily interpretable.\",\\n            \"b\": \"They require structured data.\",\\n            \"c\": \"They can be \\'black boxes\\' with interpretability challenges.\",\\n            \"d\": \"They are not scalable.\"\\n        },\\n        \"correct\": \"c\"\\n    },\\n    \"9\": {\\n        \"mcq\": \"In what area is computer vision NOT commonly used?\",\\n        \"options\": {\\n            \"a\": \"Automotive industry\",\\n            \"b\": \"Healthcare\",\\n            \"c\": \"Retail\",\\n            \"d\": \"Cooking\"\\n        },\\n        \"correct\": \"d\"\\n    },\\n    \"10\": {\\n        \"mcq\": \"What is a significant advantage of using autoencoders?\",\\n        \"options\": {\\n            \"a\": \"They require labeled data.\",\\n            \"b\": \"They can compress data for anomaly detection.\",\\n            \"c\": \"They are easy to train.\",\\n            \"d\": \"They are only used for image data.\"\\n        },\\n        \"correct\": \"b\"\\n    }\\n}\\n'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Remove Markdown code block delimiters (and an optional \"json\" label)\n",
    "cleaned_quiz = re.sub(r\"^```(?:json)?\\n|```$\", \"\", quiz.strip())\n",
    "print(repr(cleaned_quiz))  # Check the cleaned version\n",
    "quiz_data = json.loads(cleaned_quiz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quiz=json.loads(cleaned_quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data = []\n",
    "for key, value in quiz_data.items():\n",
    "    mcq = value[\"mcq\"]\n",
    "    options = \" | \".join(\n",
    "        [\n",
    "            f\"{option}: {option_value}\"\n",
    "            for option, option_value in value[\"options\"].items()\n",
    "            ]\n",
    "        )\n",
    "    correct = value[\"correct\"]\n",
    "    quiz_table_data.append({\"MCQ\": mcq, \"Choices\": options, \"Correct\": correct})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'MCQ': 'What is the primary difference between deep learning and traditional machine learning?',\n",
       "  'Choices': 'a: Deep learning uses simple neural networks. | b: Deep learning can only use supervised learning. | c: Deep learning models use three or more layers. | d: Deep learning models require labeled data.',\n",
       "  'Correct': 'c'},\n",
       " {'MCQ': 'Which of the following frameworks is NOT typically used for deep learning applications?',\n",
       "  'Choices': 'a: PyTorch | b: TensorFlow | c: JAX | d: Java',\n",
       "  'Correct': 'd'},\n",
       " {'MCQ': 'What type of neural network is primarily used for image classification tasks?',\n",
       "  'Choices': 'a: Recurrent Neural Networks (RNNs) | b: Convolutional Neural Networks (CNNs) | c: Autoencoders | d: Transformer models',\n",
       "  'Correct': 'b'},\n",
       " {'MCQ': 'What is a common disadvantage of Recurrent Neural Networks (RNNs)?',\n",
       "  'Choices': 'a: They require labeled data. | b: They have a high risk of overfitting. | c: They are prone to vanishing and exploding gradients. | d: They are not suitable for sequence data.',\n",
       "  'Correct': 'c'},\n",
       " {'MCQ': 'Which deep learning model is known for its encoder-decoder architecture?',\n",
       "  'Choices': 'a: Convolutional Neural Networks (CNNs) | b: Generative Adversarial Networks (GANs) | c: Transformer models | d: Variational Autoencoders (VAEs)',\n",
       "  'Correct': 'c'},\n",
       " {'MCQ': 'What is the main advantage of using Generative Adversarial Networks (GANs)?',\n",
       "  'Choices': 'a: They are easy to interpret. | b: They require minimal computational resources. | c: They can create realistic outputs resembling real data. | d: They do not require labeled data.',\n",
       "  'Correct': 'c'},\n",
       " {'MCQ': 'Which of the following is a key feature of diffusion models?',\n",
       "  'Choices': 'a: They use adversarial training. | b: They add Gaussian noise to training data. | c: They primarily work with text data. | d: They are prone to mode collapse.',\n",
       "  'Correct': 'b'},\n",
       " {'MCQ': 'What is one potential weakness of deep learning models?',\n",
       "  'Choices': \"a: They are easily interpretable. | b: They require structured data. | c: They can be 'black boxes' with interpretability challenges. | d: They are not scalable.\",\n",
       "  'Correct': 'c'},\n",
       " {'MCQ': 'In what area is computer vision NOT commonly used?',\n",
       "  'Choices': 'a: Automotive industry | b: Healthcare | c: Retail | d: Cooking',\n",
       "  'Correct': 'd'},\n",
       " {'MCQ': 'What is a significant advantage of using autoencoders?',\n",
       "  'Choices': 'a: They require labeled data. | b: They can compress data for anomaly detection. | c: They are easy to train. | d: They are only used for image data.',\n",
       "  'Correct': 'b'}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=pd.DataFrame(quiz_table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz.to_csv(\"Deeplearning.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'02_19_2025_20_43_40'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().strftime('%m_%d_%Y_%H_%M_%S')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
